# Text Cleaning System - æ–‡æœ¬æ¸…ç†ç³»ç»Ÿ

åŸºäº Qwen2-VL æ¨¡å‹çš„å¤šGPUå¹¶è¡Œæ–‡æœ¬æ¸…ç†å’Œæ ¼å¼éªŒè¯ç³»ç»Ÿã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
refine_action/
â”œâ”€â”€ clean_text_dataset.py        # æ•°æ®é›†åŠ è½½æ¨¡å—
â”œâ”€â”€ clean_text_prompt.py         # æç¤ºè¯æ„å»ºæ¨¡å—
â”œâ”€â”€ text_format_validator.py     # æ ¼å¼éªŒè¯æ¨¡å—
â”œâ”€â”€ run_clean_text.py            # ä¸»æ¨ç†è„šæœ¬
â””â”€â”€ README.md                    # ä½¿ç”¨æ–‡æ¡£

scripts/
â””â”€â”€ clean_text_comm.sh           # æ‰§è¡Œè„šæœ¬
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®é›†

æ•°æ®é›†æ ¼å¼ï¼ˆJSONLï¼‰ï¼š
```json
{
  "id": "WikiHow_40810_1",
  "text_demo": "Back Up Messages in the Future...\n\nStep 1: Click...\nBy now, our progress is 0.12.\n\nStep 2: ...",
  "total_steps": "8"
}
```

**å¿…éœ€å­—æ®µ**ï¼š
- `id`: æ ·æœ¬å”¯ä¸€æ ‡è¯†
- `text_demo`: åŸå§‹æ–‡æœ¬æ¼”ç¤ºå†…å®¹
- `total_steps`: æ€»æ­¥éª¤æ•°ï¼ˆå­—ç¬¦ä¸²æˆ–æ•´æ•°ï¼‰

**å¯é€‰å­—æ®µ**ï¼š
- `stage_to_estimate`, `progress_score`, `data_source` ç­‰ï¼ˆä¼šè¢«ä¿ç•™ä½†ä¸ä½¿ç”¨ï¼‰

### 2. é…ç½®æ‰§è¡Œè„šæœ¬

ç¼–è¾‘ `scripts/clean_text_comm.sh`ï¼š

```bash
# æ¨¡å‹è·¯å¾„
MODEL_PATH="/path/to/Qwen2.5-VL-3B-Instruct"

# æ•°æ®é›†è·¯å¾„
DATASET_PATH="/path/to/your/dataset.jsonl"

# è¾“å‡ºç›®å½•
OUTPUT_DIR="/path/to/output/directory"

# GPUé…ç½®
GPU_IDS="0,1,2,3,4,5,6,7"  # ä½¿ç”¨çš„GPUåˆ—è¡¨
BATCH_SIZE=32              # æ¯ä¸ªGPUçš„æ‰¹é‡å¤§å°

# æ¨ç†é…ç½®
NUM_INFERENCES=1           # æ¯ä¸ªæ ·æœ¬çš„æ¨ç†æ¬¡æ•°
TEMPERATURE=0.3            # é‡‡æ ·æ¸©åº¦ï¼ˆ0.3è¾ƒä½ï¼Œæ›´ä¸€è‡´ï¼‰
MAX_NEW_TOKENS=2048        # æœ€å¤§ç”Ÿæˆtokenæ•°

# å¤„ç†å‚æ•°
LIMIT=-1                   # é™åˆ¶å¤„ç†æ ·æœ¬æ•°ï¼ˆ-1è¡¨ç¤ºå…¨éƒ¨ï¼‰
```

### 3. æ‰§è¡Œæ¨ç†

```bash
cd /Users/cxqian/Codes/WorldVLM/data_preprocess/qwen_rollouts
bash scripts/clean_text_comm.sh
```

## ğŸ“Š è¾“å‡ºæ ¼å¼

### ä¸»è¦è¾“å‡ºæ–‡ä»¶

**cleaned_text_TIMESTAMP.jsonl** - æ¸…ç†åçš„ç»“æœï¼š
```json
{
  "id": "WikiHow_40810_1",
  "new_text_demo": "Back Up Messages in the Future...",
  "error": false,
  "format_error": false
}
```

**è¾“å‡ºå­—æ®µè¯´æ˜**ï¼š
- `id`: æ ·æœ¬ID
- `new_text_demo`: æ¨¡å‹è¾“å‡ºçš„æ¸…ç†åæ–‡æœ¬
- `error`: æ¨ç†è¿‡ç¨‹æ˜¯å¦å‡ºé”™ï¼ˆTrue/Falseï¼‰
- `format_error`: æ ¼å¼éªŒè¯æ˜¯å¦å¤±è´¥ï¼ˆTrue/Falseï¼‰
- `error_message`: é”™è¯¯ä¿¡æ¯ï¼ˆä»…åœ¨å‡ºé”™æ—¶å­˜åœ¨ï¼‰
- `format_errors`: æ ¼å¼é”™è¯¯è¯¦æƒ…ï¼ˆä»…åœ¨verboseæ¨¡å¼ä¸‹å­˜åœ¨ï¼‰

### è¾…åŠ©è¾“å‡ºæ–‡ä»¶

- **cleaned_text_TIMESTAMP_summary.json** - ç»Ÿè®¡æ‘˜è¦
- **cleaned_text_TIMESTAMP_gpuX.jsonl** - å„GPUçš„ä¸­é—´ç»“æœ
- **clean_text_TIMESTAMP.log** - å®Œæ•´æ—¥å¿—

## ğŸ” æ ¼å¼éªŒè¯è§„åˆ™

ç³»ç»Ÿä¼šè‡ªåŠ¨éªŒè¯è¾“å‡ºæ–‡æœ¬æ˜¯å¦ç¬¦åˆä»¥ä¸‹è§„èŒƒï¼š

1. âœ… `total_steps` ä¸ºæ­£æ•´æ•°
2. âœ… åŒ…å«æ‰€æœ‰æ­¥éª¤ï¼ˆStep 1 åˆ° Step Nï¼‰ï¼Œä¸è·³æ­¥ã€ä¸é‡å¤
3. âœ… æ¯ä¸ªæ­¥éª¤åæœ‰æ­£ç¡®çš„è¿›åº¦æ ‡è®°ï¼š`By now, our progress is X`
   - X = step_number / total_steps
   - æ”¯æŒå¤šç§æµ®ç‚¹æ•°æ ¼å¼ï¼š0.2, 0.20, 1.0, 1 ç­‰
4. âœ… ä¸å­˜åœ¨å¤šä½™æ­¥éª¤ï¼ˆStep N+1ï¼‰

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### ç›´æ¥ä½¿ç”¨ Python è„šæœ¬

```bash
cd refine_action

python run_clean_text.py \
    --model-path /path/to/model \
    --dataset-path /path/to/dataset.jsonl \
    --output-file /path/to/output.jsonl \
    --batch-size 32 \
    --num-inferences 1 \
    --temperature 0.3 \
    --top-p 0.9 \
    --top-k 50 \
    --max-new-tokens 2048 \
    --limit -1
```

### å‚æ•°è¯´æ˜

**å¿…éœ€å‚æ•°**ï¼š
- `--model-path`: Qwen2-VLæ¨¡å‹è·¯å¾„
- `--dataset-path`: è¾“å…¥æ•°æ®é›†è·¯å¾„
- `--output-file`: è¾“å‡ºæ–‡ä»¶è·¯å¾„

**å¯é€‰å‚æ•°**ï¼š
- `--batch-size`: æ¯ä¸ªGPUçš„æ‰¹é‡å¤§å°ï¼ˆé»˜è®¤ï¼š16ï¼‰
- `--num-inferences`: æ¯ä¸ªæ ·æœ¬çš„æ¨ç†æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š1ï¼‰
- `--limit`: é™åˆ¶å¤„ç†æ ·æœ¬æ•°ï¼ˆé»˜è®¤ï¼š-1ï¼Œå¤„ç†å…¨éƒ¨ï¼‰
- `--temperature`: é‡‡æ ·æ¸©åº¦ï¼ˆé»˜è®¤ï¼š0.3ï¼‰
- `--top-p`: Top-pé‡‡æ ·å‚æ•°ï¼ˆé»˜è®¤ï¼š0.9ï¼‰
- `--top-k`: Top-ké‡‡æ ·å‚æ•°ï¼ˆé»˜è®¤ï¼š50ï¼‰
- `--max-new-tokens`: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼ˆé»˜è®¤ï¼š2048ï¼‰
- `--verbose`: æ‰“å°è¯¦ç»†è¾“å‡º

## ğŸ“ˆ æ€§èƒ½ä¼°ç®—

å‡è®¾é…ç½®ï¼š
- **8ä¸ªGPU**
- **æ¯ä¸ªGPU batch_size=32**
- **1000ä¸ªæ ·æœ¬**
- **æ¯ä¸ªæ ·æœ¬å¹³å‡300 tokensè¾“å‡º**

é¢„è®¡æ€§èƒ½ï¼š
- å¹¶è¡Œæ‰¹æ¬¡æ•°ï¼š1000 / (8 Ã— 32) â‰ˆ 4 æ‰¹æ¬¡
- æ¯æ‰¹æ¬¡æ—¶é—´ï¼š~30ç§’ï¼ˆå–å†³äºæ¨¡å‹å’Œç¡¬ä»¶ï¼‰
- **æ€»æ—¶é—´ï¼š~2-3åˆ†é’Ÿ**

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šGPUå†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å‡å° `BATCH_SIZE`
2. å‡å° `MAX_NEW_TOKENS`
3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹

### é—®é¢˜ï¼šæ ¼å¼é”™è¯¯ç‡é«˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. é™ä½ `TEMPERATURE`ï¼ˆæ›´ç¡®å®šæ€§çš„è¾“å‡ºï¼‰
2. è°ƒæ•´æç¤ºè¯ï¼ˆç¼–è¾‘ `clean_text_prompt.py`ï¼‰
3. å¢åŠ  `NUM_INFERENCES`ï¼Œé€‰æ‹©æœ€ä½³ç»“æœ

### é—®é¢˜ï¼šè¿›ç¨‹å¡ä½

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥GPUæ˜¯å¦æ­£å¸¸å·¥ä½œ
2. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š`cat clean_text_TIMESTAMP.log`
3. ä½¿ç”¨ Ctrl+C ä¸­æ–­ï¼Œç³»ç»Ÿä¼šä¿å­˜éƒ¨åˆ†ç»“æœåˆ° `*_partial.jsonl`

## ğŸ“ ç¤ºä¾‹ç»Ÿè®¡è¾“å‡º

```
======================================================================
TEXT CLEANING SUMMARY
======================================================================
Total samples (expanded): 1000
Original samples: 1000
Inferences per sample: 1
Processed: 1000
Processing errors: 5 (0.50%)
Format errors: 23 (2.30%)
Valid samples: 977 (97.70%)
Results saved to: /path/to/output.jsonl
======================================================================
```

## ğŸ”— ç›¸å…³æ¨¡å—

- **æ•°æ®åŠ è½½**: `clean_text_dataset.py`
- **æç¤ºè¯æ„å»º**: `clean_text_prompt.py`
- **æ ¼å¼éªŒè¯**: `text_format_validator.py`
- **ä¸»æ¨ç†**: `run_clean_text.py`
- **æ¨¡å‹æ¥å£**: `../qwen2_vl/model.py`

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª WorldVLM é¡¹ç›®çš„è®¸å¯è¯ã€‚
