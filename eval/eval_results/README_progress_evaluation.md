# Progress Estimation Evaluation Module

å®Œæ•´çš„è¿›åº¦ä¼°è®¡è¯„ä¼°å·¥å…·ï¼Œæ”¯æŒ N/A å€¼å¤„ç†ã€False Positive æ£€æµ‹å’Œè½¨è¿¹é¡ºåºä¸€è‡´æ€§ï¼ˆVOCï¼‰è®¡ç®—ã€‚

## åŠŸèƒ½ç‰¹æ€§

### âœ… æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡

1. **è¯¯å·®è®¡ç®—**
   - ç›¸å¯¹è¯¯å·®ï¼ˆScore Errorï¼‰: `|GT - Pred| / GT`
   - ç»å¯¹è¯¯å·®ï¼ˆRef Errorï¼‰: `|GT - Pred|`
   - ä»…åœ¨ GT å’Œé¢„æµ‹éƒ½æ˜¯æ•°å€¼æ—¶è®¡ç®—

2. **False Positive æ£€æµ‹**
   - Ref False Positive: GT å’Œé¢„æµ‹çš„ n/a çŠ¶æ€ä¸åŒ¹é…
   - Score False Positive: GT å’Œé¢„æµ‹çš„ n/a çŠ¶æ€ä¸åŒ¹é…
   - ç¤ºä¾‹ï¼šGT æ˜¯æ•°å€¼ä½†é¢„æµ‹æ˜¯ n/aï¼Œæˆ– GT æ˜¯ n/a ä½†é¢„æµ‹æ˜¯æ•°å€¼

3. **VOC (Visual/Trajectory Order Consistency)**
   - ä½¿ç”¨ Spearman ç›¸å…³æ€§è¯„ä¼°è½¨è¿¹æ’åºä¸€è‡´æ€§
   - æŒ‰è½¨è¿¹ ID åˆ†ç»„è®¡ç®—
   - ä»…åœ¨ GT ä¸ºæ•°å€¼çš„è½¨è¿¹ä¸Šè®¡ç®—

4. **GT åˆ†å¸ƒç»Ÿè®¡**
   - æ•°å€¼ GT æ ·æœ¬æ•°é‡
   - N/A GT æ ·æœ¬æ•°é‡
   - åˆ†åˆ«ç»Ÿè®¡ ref å’Œ score

## å®‰è£…ä¾èµ–

```bash
pip install numpy scipy
```

## ä½¿ç”¨æ–¹æ³•

### 1. å‘½ä»¤è¡Œä½¿ç”¨

#### è¯„ä¼°å•ä¸ªæ–‡ä»¶

```bash
# åŸºç¡€è¯„ä¼°
python progress_evaluation.py results.jsonl

# ä¿å­˜æ‘˜è¦åˆ°æŒ‡å®šæ–‡ä»¶
python progress_evaluation.py results.jsonl --output summary.json
```

#### æ¯”è¾ƒå¤šä¸ªæ¨¡å‹

```bash
python progress_evaluation.py --compare \
    baseline:results_baseline.jsonl \
    sft_3b:results_sft_3b.jsonl \
    sft_7b:results_sft_7b.jsonl \
    --output comparison.json
```

### 2. Python API ä½¿ç”¨

#### åŸºç¡€è¯„ä¼°

```python
from progress_evaluation import generate_summary_report

# è¯„ä¼°å•ä¸ªæ–‡ä»¶
stats = generate_summary_report('results.jsonl')

print(f"Score Error Mean: {stats['score_error_mean']:.4f}")
print(f"VOC Mean: {stats['voc_mean']:.4f}")
print(f"Score FP Rate: {stats['score_fp_rate']*100:.2f}%")
```

#### åŠ è½½å’Œåˆ†æ

```python
from progress_evaluation import load_results, analyze_results

# åŠ è½½ç»“æœ
results = load_results('results.jsonl')

# åˆ†æï¼ˆå¸¦è¯¦ç»†è¾“å‡ºï¼‰
stats = analyze_results(results, verbose=True)

# åˆ†æï¼ˆé™é»˜æ¨¡å¼ï¼‰
stats = analyze_results(results, verbose=False)
```

#### æ¨¡å‹æ¯”è¾ƒ

```python
from progress_evaluation import compare_models

# æ¯”è¾ƒå¤šä¸ªæ¨¡å‹
result_files = {
    'Baseline': 'results_baseline.jsonl',
    'SFT-3B': 'results_sft_3b.jsonl',
    'SFT-7B': 'results_sft_7b.jsonl'
}

comparison = compare_models(result_files, output_file='comparison.json')

# è®¿é—®ç‰¹å®šæ¨¡å‹çš„ç»Ÿè®¡
baseline_stats = comparison['Baseline']
print(f"Baseline VOC: {baseline_stats['voc_mean']:.4f}")
```

#### ä½¿ç”¨æ ¸å¿ƒå‡½æ•°

```python
from progress_evaluation import (
    calculate_false_positives,
    calculate_evaluation_score,
    calculate_ref_error,
    calculate_voc_metrics
)

# è®¡ç®— False Positive
ref_fp, score_fp = calculate_false_positives(
    predicted_ref=5,        # æˆ– "n/a"
    predicted_score=0.33,   # æˆ– "n/a"
    gt_ref=3,              # æˆ– None
    gt_score=0.30          # æˆ– None
)

# è®¡ç®—è¯„ä¼°è¯¯å·®
score_error = calculate_evaluation_score(
    predicted=0.33,
    ground_truth=0.30
)

# è®¡ç®—å‚è€ƒè¯¯å·®
ref_error = calculate_ref_error(
    predicted_ref=5,
    ground_truth_ref=3
)

# è®¡ç®— VOC
voc_metrics = calculate_voc_metrics(results)
print(f"VOC Mean: {voc_metrics['voc_mean']:.4f}")
print(f"VOC Std: {voc_metrics['voc_std']:.4f}")
print(f"Valid Trajectories: {voc_metrics['voc_count']}")
```

## è¾“å‡ºæ ¼å¼

### è¯„ä¼°ç»Ÿè®¡å­—å…¸

```python
{
    # åŸºç¡€ç»Ÿè®¡
    'total_samples': 1000,
    'valid_samples': 950,
    'error_samples': 50,
    'error_rate': 0.05,

    # Score è¯¯å·®ç»Ÿè®¡
    'score_error_mean': 0.1234,
    'score_error_median': 0.0987,
    'score_error_std': 0.0543,
    'score_error_count': 900,

    # Ref è¯¯å·®ç»Ÿè®¡
    'ref_error_mean': 1.5678,
    'ref_error_median': 1.0000,
    'ref_error_std': 0.8765,
    'ref_error_count': 920,

    # False Positive ç»Ÿè®¡
    'ref_fp_count': 45,
    'ref_fp_rate': 0.045,
    'score_fp_count': 38,
    'score_fp_rate': 0.038,

    # VOC ç»Ÿè®¡
    'voc_mean': 0.8765,
    'voc_std': 0.1234,
    'voc_median': 0.9012,
    'voc_count': 120,

    # GT åˆ†å¸ƒ
    'gt_numeric_count': 850,
    'gt_na_count': 150,
    'gt_ref_numeric': 920,
    'gt_ref_na': 80,
    'gt_score_numeric': 900,
    'gt_score_na': 100
}
```

### å‘½ä»¤è¡Œè¾“å‡ºç¤ºä¾‹

```
================================================================================
PROGRESS ESTIMATION EVALUATION REPORT
================================================================================

ğŸ“Š Basic Statistics:
  Total samples:     1000
  Valid samples:     950
  Error samples:     50 (5.00%)

ğŸ“ˆ Score Error Metrics:
  Mean error:        0.1234
  Median error:      0.0987
  Std error:         0.0543
  Valid samples:     900/1000

ğŸ“ Ref Error Metrics:
  Mean error:        1.5678
  Median error:      1.0000
  Std error:         0.8765
  Valid samples:     920/1000

âš ï¸  False Positive Rates:
  Ref FP rate:       4.50% (45/1000)
  Score FP rate:     3.80% (38/1000)

ğŸ”„ VOC (Trajectory Order Consistency):
  Mean VOC:          0.8765
  Median VOC:        0.9012
  Std VOC:           0.1234
  Valid trajectories: 120

ğŸ“‹ Ground Truth Distribution:
  Both numeric:      850 (85.0%)
  Contains N/A:      150 (15.0%)
    - Ref numeric:   920
    - Ref N/A:       80
    - Score numeric: 900
    - Score N/A:     100
================================================================================
```

## æ•°æ®æ ¼å¼è¦æ±‚

### è¾“å…¥ JSONL æ ¼å¼

æ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{
  "ref": "3",           // æˆ– "n/a"
  "score": "33%",       // æˆ– "n/a" æˆ– "0.33"
  "closest_idx": 3,     // GT ref (1-based)
  "ground_truth_score": "33%",
  "ref_score": 0.1234,  // å¯é€‰ï¼šé¢„è®¡ç®—çš„ ref è¯¯å·®
  "pred_score": 0.0987, // å¯é€‰ï¼šé¢„è®¡ç®—çš„ score è¯¯å·®
  "ref_false_positive": false,
  "score_false_positive": false,
  "response": "...",    // åŸå§‹æ¨¡å‹è¾“å‡º
  "meta_data": {
    "id": "trajectory_001",  // è½¨è¿¹ ID
    "closest_idx": 3,        // GT ref
    "progress_score": 0.33,  // GT score (0-1)ï¼Œæˆ– null è¡¨ç¤º n/a
    "status": "success"      // æˆ– "failed"
  }
}
```

### N/A å€¼è¡¨ç¤º

- **GT ä¸­çš„ N/A**: `meta_data` ä¸­çš„ `closest_idx` æˆ– `progress_score` ä¸º `null`
- **é¢„æµ‹ä¸­çš„ N/A**: `ref` æˆ– `score` å­—æ®µä¸ºå­—ç¬¦ä¸² `"n/a"`

## è¯„ä¼°é€»è¾‘è¯´æ˜

### 1. False Positive å®šä¹‰

False Positive å‘ç”Ÿåœ¨ä»¥ä¸‹æƒ…å†µï¼š
- **GT æ˜¯æ•°å€¼ + é¢„æµ‹æ˜¯ n/a**: æ¨¡å‹åº”è¯¥é¢„æµ‹æ•°å€¼ä½†é¢„æµ‹äº† n/a
- **GT æ˜¯ n/a + é¢„æµ‹æ˜¯æ•°å€¼**: æ¨¡å‹åº”è¯¥é¢„æµ‹ n/a ä½†é¢„æµ‹äº†æ•°å€¼

æ­£ç¡®çš„æƒ…å†µï¼š
- **GT æ˜¯æ•°å€¼ + é¢„æµ‹æ˜¯æ•°å€¼**: ä½¿ç”¨è¯¯å·®è®¡ç®—
- **GT æ˜¯ n/a + é¢„æµ‹æ˜¯ n/a**: æ­£ç¡®è¯†åˆ« n/a

### 2. æ¡ä»¶æ€§è¯¯å·®è®¡ç®—

ä»…åœ¨ä»¥ä¸‹æ¡ä»¶ä¸‹è®¡ç®—è¯¯å·®ï¼š
- **GT å’Œé¢„æµ‹éƒ½æ˜¯æ•°å€¼**: è®¡ç®—ç›¸å¯¹è¯¯å·®æˆ–ç»å¯¹è¯¯å·®
- **å…¶ä»–æƒ…å†µ**: è¿”å› `inf`ï¼Œä¸è®¡å…¥ç»Ÿè®¡

### 3. VOC è®¡ç®—æµç¨‹

1. æŒ‰è½¨è¿¹ ID åˆ†ç»„æ‰€æœ‰æ ·æœ¬
2. **ä»…ä¿ç•™ GT ä¸ºæ•°å€¼çš„è½¨è¿¹**
3. å¯¹æ¯ä¸ªè½¨è¿¹ï¼š
   - æŒ‰ GT score æ’åºå¾—åˆ°çœŸå®é¡ºåº
   - æŒ‰é¢„æµ‹ score æ’åºå¾—åˆ°é¢„æµ‹é¡ºåºï¼ˆn/a â†’ 0.0ï¼‰
   - è®¡ç®— Spearman ç›¸å…³æ€§
4. è¿”å›æ‰€æœ‰æœ‰æ•ˆè½¨è¿¹çš„ VOC å‡å€¼ã€ä¸­ä½æ•°å’Œæ ‡å‡†å·®

### 4. GT åˆ†å¸ƒç»Ÿè®¡

åˆ†åˆ«ç»Ÿè®¡ï¼š
- ä¸¤è€…éƒ½æ˜¯æ•°å€¼çš„æ ·æœ¬æ•°
- è‡³å°‘ä¸€ä¸ªæ˜¯ n/a çš„æ ·æœ¬æ•°
- ref ä¸ºæ•°å€¼/n/a çš„æ ·æœ¬æ•°
- score ä¸ºæ•°å€¼/n/a çš„æ ·æœ¬æ•°

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆæˆ‘çš„ VOC æ˜¯ Noneï¼Ÿ

**A**: VOC éœ€è¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š
- è‡³å°‘æœ‰ä¸€ä¸ªè½¨è¿¹åŒ…å« 2 ä¸ªæˆ–ä»¥ä¸Šæ ·æœ¬
- GT çš„ `closest_idx` å’Œ `progress_score` éƒ½å¿…é¡»æ˜¯æ•°å€¼
- è½¨è¿¹å†…çš„ GT score å¿…é¡»æœ‰å˜åŒ–ï¼ˆä¸èƒ½éƒ½ç›¸åŒï¼‰

### Q2: è¯¯å·®è®¡ç®—ä¸ºä»€ä¹ˆè¿”å› infï¼Ÿ

**A**: ä»¥ä¸‹æƒ…å†µä¼šè¿”å› infï¼š
- GT æˆ–é¢„æµ‹ä¸º None
- GT æˆ–é¢„æµ‹ä¸º "n/a"
- GT ä¸º 0ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰

### Q3: å¦‚ä½•å¤„ç†ç™¾åˆ†æ¯”æ ¼å¼ï¼Ÿ

**A**: æ¨¡å—è‡ªåŠ¨å¤„ç†ä»¥ä¸‹æ ¼å¼ï¼š
- `"33%"` â†’ 0.33
- `"0.33"` â†’ 0.33
- `33` â†’ 0.33ï¼ˆå‡è®¾æ˜¯ç™¾åˆ†æ¯”ï¼‰
- `0.33` â†’ 0.33

### Q4: False Positive å’Œé”™è¯¯æ ·æœ¬çš„åŒºåˆ«ï¼Ÿ

**A**:
- **False Positive**: GT å’Œé¢„æµ‹çš„ n/a çŠ¶æ€ä¸åŒ¹é…
- **é”™è¯¯æ ·æœ¬**: `meta_data.status == "failed"`ï¼Œé€šå¸¸æ˜¯è§£æé”™è¯¯æˆ–éªŒè¯å¤±è´¥

## ä¸åŸå§‹ eval_results.py çš„åŒºåˆ«

| ç‰¹æ€§ | åŸå§‹ç‰ˆæœ¬ | æ–°ç‰ˆæœ¬ (progress_evaluation.py) |
|------|---------|--------------------------------|
| N/A æ”¯æŒ | âŒ | âœ… å®Œæ•´æ”¯æŒ |
| False Positive | âŒ | âœ… Ref å’Œ Score åˆ†åˆ«è·Ÿè¸ª |
| VOC è®¡ç®— | âš ï¸ ç®€å•ç‰ˆæœ¬ | âœ… å®Œæ•´ Spearman ç›¸å…³æ€§ |
| æ¡ä»¶æ€§è¯¯å·® | âŒ | âœ… ä»…æ•°å€¼å¯¹è®¡ç®— |
| GT åˆ†å¸ƒç»Ÿè®¡ | âŒ | âœ… è¯¦ç»†ç»Ÿè®¡ |
| æ¨¡å‹æ¯”è¾ƒ | âŒ | âœ… å†…ç½®æ¯”è¾ƒåŠŸèƒ½ |
| æ–‡æ¡£ | âš ï¸ æœ€å°‘ | âœ… å®Œæ•´æ–‡æ¡£å’Œç±»å‹æ³¨è§£ |

## è´¡çŒ®å’Œåé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿã€‚

## ç‰ˆæœ¬å†å²

- **v1.0** (2025-01): åˆå§‹ç‰ˆæœ¬ï¼Œå®Œæ•´çš„ N/A æ”¯æŒå’Œè¯„ä¼°åŠŸèƒ½
