{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å°†HDF5å›¾åƒæ•°æ®è½¬æ¢ä¸ºè§†é¢‘\n",
    "\n",
    "æœ¬notebookç”¨äºä»RoboMindæ•°æ®é›†çš„HDF5æ–‡ä»¶ä¸­æå–RGBå›¾åƒåºåˆ—å¹¶ç”Ÿæˆè§†é¢‘æ–‡ä»¶ã€‚\n",
    "\n",
    "## åŠŸèƒ½ç‰¹æ€§\n",
    "\n",
    "- âœ… è§£ç å‹ç¼©çš„å›¾åƒæ•°æ®\n",
    "- âœ… æ”¯æŒå¤šç›¸æœºè§†è§’ï¼ˆchest, headï¼‰\n",
    "- âœ… ç”Ÿæˆå•ç‹¬ç›¸æœºè§†é¢‘\n",
    "- âœ… ç”Ÿæˆå¹¶æ’å¯¹æ¯”è§†é¢‘\n",
    "- âœ… æ·»åŠ ä¿¡æ¯è¦†ç›–å±‚ï¼ˆå¸§å·ã€æ—¶é—´æˆ³ç­‰ï¼‰\n",
    "- âœ… æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶\n",
    "- âœ… è¿›åº¦æ¡æ˜¾ç¤º\n",
    "\n",
    "## ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "1. é…ç½®å‚æ•°ï¼ˆç¬¬2ä¸ªcellï¼‰\n",
    "2. è¿è¡Œé¢„è§ˆï¼ˆç¬¬4ä¸ªcellï¼‰\n",
    "3. ç”Ÿæˆè§†é¢‘ï¼ˆç¬¬5-7ä¸ªcellsï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰€æœ‰ä¾èµ–å·²å¯¼å…¥\n",
      "OpenCVç‰ˆæœ¬: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰ä¾èµ–å·²å¯¼å…¥\")\n",
    "print(f\"OpenCVç‰ˆæœ¬: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é…ç½®å·²åŠ è½½\n",
      "è¾“å…¥æ–‡ä»¶: /projects/p32958/chengxuan/data/robomind_fail/failure_data/135-place_cup_on_blue_bowl_with_left_hand/å¤¹å–å‰ç¢°æ’/1135137-2025_03_05_16_57_11/data/trajectory.hdf5\n",
      "è¾“å‡ºç›®å½•: /projects/p32958/chengxuan/data/robomind_fail/failure_data/135-place_cup_on_blue_bowl_with_left_hand/å¤¹å–å‰ç¢°æ’/1135137-2025_03_05_16_57_11/videos\n",
      "å¸§ç‡: 30 FPS\n",
      "ç¼–ç å™¨: mp4v\n"
     ]
    }
   ],
   "source": [
    "# ==================== ä¸»è¦é…ç½® ====================\n",
    "\n",
    "# HDF5æ–‡ä»¶è·¯å¾„\n",
    "H5_PATH = \"/projects/p32958/chengxuan/data/robomind_fail/failure_data/135-place_cup_on_blue_bowl_with_left_hand/å¤¹å–å‰ç¢°æ’/1135137-2025_03_05_16_57_11/data/trajectory.hdf5\"\n",
    "\n",
    "# è¾“å‡ºç›®å½•\n",
    "OUTPUT_DIR = \"/projects/b1222/userdata/jianshu/chengxuan/saved/videos\"\n",
    "\n",
    "# è§†é¢‘é…ç½®\n",
    "VIDEO_CONFIG = {\n",
    "    'fps': 30,                    # å¸§ç‡\n",
    "    'codec': 'mp4v',              # ç¼–ç å™¨: 'mp4v', 'avc1', 'H264', 'XVID'\n",
    "    'quality': 95,                # è´¨é‡ (0-100, ä»…å¯¹æŸäº›ç¼–ç å™¨æœ‰æ•ˆ)\n",
    "    'resize': None,               # è°ƒæ•´å¤§å° (width, height) æˆ– None ä¿æŒåŸå§‹\n",
    "    'add_frame_number': True,     # æ˜¯å¦æ·»åŠ å¸§å·\n",
    "    'add_timestamp': True,        # æ˜¯å¦æ·»åŠ æ—¶é—´æˆ³\n",
    "    'add_task_name': True,        # æ˜¯å¦æ·»åŠ ä»»åŠ¡åç§°\n",
    "}\n",
    "\n",
    "# è¦å¤„ç†çš„ç›¸æœºåˆ—è¡¨\n",
    "CAMERAS = ['camera_chest', 'camera_head']\n",
    "\n",
    "print(\"âœ… é…ç½®å·²åŠ è½½\")\n",
    "print(f\"è¾“å…¥æ–‡ä»¶: {H5_PATH}\")\n",
    "print(f\"è¾“å‡ºç›®å½•: {OUTPUT_DIR}\")\n",
    "print(f\"å¸§ç‡: {VIDEO_CONFIG['fps']} FPS\")\n",
    "print(f\"ç¼–ç å™¨: {VIDEO_CONFIG['codec']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å·¥å…·å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5VideoConverter:\n",
    "    \"\"\"HDF5å›¾åƒæ•°æ®åˆ°è§†é¢‘çš„è½¬æ¢å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, h5_path: str, output_dir: str, config: dict):\n",
    "        self.h5_path = Path(h5_path)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.config = config\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # éªŒè¯æ–‡ä»¶å­˜åœ¨\n",
    "        if not self.h5_path.exists():\n",
    "            raise FileNotFoundError(f\"HDF5æ–‡ä»¶ä¸å­˜åœ¨: {self.h5_path}\")\n",
    "        \n",
    "        # åŠ è½½åŸºæœ¬ä¿¡æ¯\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            self.is_compressed = f.attrs.get('compress', True)\n",
    "            self.task_name = f['language_instruction'][()].decode('utf-8') if 'language_instruction' in f else 'Unknown Task'\n",
    "            \n",
    "            # æ£€æŸ¥å¯ç”¨çš„ç›¸æœº\n",
    "            self.available_cameras = []\n",
    "            if 'observations/rgb_images' in f:\n",
    "                self.available_cameras = list(f['observations/rgb_images'].keys())\n",
    "            \n",
    "            # è·å–æ—¶é—´åºåˆ—\n",
    "            self.time_seq = f['sim_time_seq'][:] if 'sim_time_seq' in f else None\n",
    "        \n",
    "        print(f\"âœ… è½¬æ¢å™¨åˆå§‹åŒ–æˆåŠŸ\")\n",
    "        print(f\"   ä»»åŠ¡: {self.task_name}\")\n",
    "        print(f\"   å‹ç¼©: {self.is_compressed}\")\n",
    "        print(f\"   å¯ç”¨ç›¸æœº: {self.available_cameras}\")\n",
    "    \n",
    "    def decode_image(self, compressed_data: np.ndarray) -> Optional[np.ndarray]:\n",
    "        \"\"\"è§£ç å‹ç¼©çš„å›¾åƒæ•°æ®\"\"\"\n",
    "        if compressed_data is None or len(compressed_data) == 0:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # å°è¯•ä½¿ç”¨cv2è§£ç \n",
    "            img = cv2.imdecode(compressed_data, cv2.IMREAD_COLOR)\n",
    "            \n",
    "            if img is None:\n",
    "                # å°è¯•ä½œä¸ºåŸå§‹å­—èŠ‚è§£æ\n",
    "                img = np.frombuffer(compressed_data, dtype=np.uint8)\n",
    "                \n",
    "                # æ ¹æ®å¤§å°æ¨æ–­åˆ†è¾¨ç‡\n",
    "                if img.size == 2764800:  # 720 * 1280 * 3\n",
    "                    img = img.reshape(720, 1280, 3)\n",
    "                elif img.size == 921600:  # 480 * 640 * 3\n",
    "                    img = img.reshape(480, 640, 3)\n",
    "                elif img.size == 1228800:  # 640 * 640 * 3\n",
    "                    img = img.reshape(640, 640, 3)\n",
    "                else:\n",
    "                    return None\n",
    "            \n",
    "            # BGRè½¬RGB\n",
    "            if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            return img\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"è§£ç å¤±è´¥: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_frames(self, camera_name: str) -> Tuple[int, callable]:\n",
    "        \"\"\"è·å–æŒ‡å®šç›¸æœºçš„å¸§æ•°å’Œå¸§è·å–å‡½æ•°\"\"\"\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            camera_data = f['observations/rgb_images'][camera_name]\n",
    "            num_frames = len(camera_data)\n",
    "            \n",
    "            def get_frame(idx):\n",
    "                with h5py.File(self.h5_path, 'r') as f_inner:\n",
    "                    frame_data = f_inner['observations/rgb_images'][camera_name][idx]\n",
    "                    if self.is_compressed:\n",
    "                        return self.decode_image(frame_data)\n",
    "                    else:\n",
    "                        img = frame_data\n",
    "                        if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        return img\n",
    "            \n",
    "            return num_frames, get_frame\n",
    "    \n",
    "    def add_info_overlay(self, img: np.ndarray, frame_idx: int, \n",
    "                        camera_name: str = \"\") -> np.ndarray:\n",
    "        \"\"\"åœ¨å›¾åƒä¸Šæ·»åŠ ä¿¡æ¯è¦†ç›–å±‚\"\"\"\n",
    "        img_with_info = img.copy()\n",
    "        \n",
    "        # è½¬æ¢ä¸ºBGRç”¨äºOpenCVç»˜åˆ¶\n",
    "        img_with_info = cv2.cvtColor(img_with_info, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # é…ç½®æ–‡æœ¬æ ·å¼\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.6\n",
    "        thickness = 2\n",
    "        color = (255, 255, 255)  # ç™½è‰²\n",
    "        bg_color = (0, 0, 0)      # é»‘è‰²èƒŒæ™¯\n",
    "        \n",
    "        y_offset = 30\n",
    "        \n",
    "        # æ·»åŠ ä»»åŠ¡åç§°\n",
    "        if self.config.get('add_task_name', True):\n",
    "            text = f\"Task: {self.task_name}\"\n",
    "            (w, h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "            cv2.rectangle(img_with_info, (10, y_offset - h - 5), \n",
    "                         (15 + w, y_offset + 5), bg_color, -1)\n",
    "            cv2.putText(img_with_info, text, (10, y_offset), \n",
    "                       font, font_scale, color, thickness)\n",
    "            y_offset += 35\n",
    "        \n",
    "        # æ·»åŠ ç›¸æœºåç§°\n",
    "        if camera_name:\n",
    "            text = f\"Camera: {camera_name}\"\n",
    "            (w, h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "            cv2.rectangle(img_with_info, (10, y_offset - h - 5), \n",
    "                         (15 + w, y_offset + 5), bg_color, -1)\n",
    "            cv2.putText(img_with_info, text, (10, y_offset), \n",
    "                       font, font_scale, color, thickness)\n",
    "            y_offset += 35\n",
    "        \n",
    "        # æ·»åŠ å¸§å·\n",
    "        if self.config.get('add_frame_number', True):\n",
    "            text = f\"Frame: {frame_idx}\"\n",
    "            (w, h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "            cv2.rectangle(img_with_info, (10, y_offset - h - 5), \n",
    "                         (15 + w, y_offset + 5), bg_color, -1)\n",
    "            cv2.putText(img_with_info, text, (10, y_offset), \n",
    "                       font, font_scale, color, thickness)\n",
    "            y_offset += 35\n",
    "        \n",
    "        # æ·»åŠ æ—¶é—´æˆ³\n",
    "        if self.config.get('add_timestamp', True) and self.time_seq is not None:\n",
    "            if frame_idx < len(self.time_seq):\n",
    "                text = f\"Time: {self.time_seq[frame_idx]:.3f}s\"\n",
    "                (w, h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "                cv2.rectangle(img_with_info, (10, y_offset - h - 5), \n",
    "                             (15 + w, y_offset + 5), bg_color, -1)\n",
    "                cv2.putText(img_with_info, text, (10, y_offset), \n",
    "                           font, font_scale, color, thickness)\n",
    "        \n",
    "        # è½¬æ¢å›RGB\n",
    "        img_with_info = cv2.cvtColor(img_with_info, cv2.COLOR_BGR2RGB)\n",
    "        return img_with_info\n",
    "    \n",
    "    def create_single_camera_video(self, camera_name: str, \n",
    "                                   add_info: bool = False) -> Path:\n",
    "        \"\"\"ä¸ºå•ä¸ªç›¸æœºåˆ›å»ºè§†é¢‘\"\"\"\n",
    "        print(f\"\\nğŸ¬ å¼€å§‹ç”Ÿæˆ {camera_name} è§†é¢‘...\")\n",
    "        \n",
    "        if camera_name not in self.available_cameras:\n",
    "            raise ValueError(f\"ç›¸æœº {camera_name} ä¸å¯ç”¨. å¯ç”¨ç›¸æœº: {self.available_cameras}\")\n",
    "        \n",
    "        # è·å–å¸§ä¿¡æ¯\n",
    "        num_frames, get_frame = self.get_frames(camera_name)\n",
    "        print(f\"   æ€»å¸§æ•°: {num_frames}\")\n",
    "        \n",
    "        # è·å–ç¬¬ä¸€å¸§ä»¥ç¡®å®šåˆ†è¾¨ç‡\n",
    "        first_frame = get_frame(0)\n",
    "        if first_frame is None:\n",
    "            raise RuntimeError(\"æ— æ³•è§£ç ç¬¬ä¸€å¸§\")\n",
    "        \n",
    "        height, width = first_frame.shape[:2]\n",
    "        \n",
    "        # åº”ç”¨resizeé…ç½®\n",
    "        if self.config.get('resize'):\n",
    "            width, height = self.config['resize']\n",
    "        \n",
    "        print(f\"   åˆ†è¾¨ç‡: {width}x{height}\")\n",
    "        \n",
    "        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨\n",
    "        suffix = \"_with_info\" if add_info else \"\"\n",
    "        output_path = self.output_dir / f\"{camera_name}{suffix}.mp4\"\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*self.config['codec'])\n",
    "        writer = cv2.VideoWriter(\n",
    "            str(output_path),\n",
    "            fourcc,\n",
    "            self.config['fps'],\n",
    "            (width, height)\n",
    "        )\n",
    "        \n",
    "        if not writer.isOpened():\n",
    "            raise RuntimeError(f\"æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨. ç¼–ç å™¨: {self.config['codec']}\")\n",
    "        \n",
    "        # é€å¸§å†™å…¥\n",
    "        for frame_idx in tqdm(range(num_frames), desc=f\"  å¤„ç† {camera_name}\"):\n",
    "            frame = get_frame(frame_idx)\n",
    "            \n",
    "            if frame is None:\n",
    "                print(f\"\\nâš ï¸  è­¦å‘Š: å¸§ {frame_idx} è§£ç å¤±è´¥ï¼Œè·³è¿‡\")\n",
    "                continue\n",
    "            \n",
    "            # æ·»åŠ ä¿¡æ¯è¦†ç›–\n",
    "            if add_info:\n",
    "                frame = self.add_info_overlay(frame, frame_idx, camera_name)\n",
    "            \n",
    "            # Resize if needed\n",
    "            if self.config.get('resize'):\n",
    "                frame = cv2.resize(frame, (width, height))\n",
    "            \n",
    "            # è½¬æ¢RGBåˆ°BGR for OpenCV\n",
    "            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            writer.write(frame_bgr)\n",
    "        \n",
    "        writer.release()\n",
    "        print(f\"âœ… è§†é¢‘å·²ä¿å­˜: {output_path}\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def create_side_by_side_video(self, cameras: List[str], \n",
    "                                  add_info: bool = False) -> Path:\n",
    "        \"\"\"åˆ›å»ºå¹¶æ’å¯¹æ¯”è§†é¢‘\"\"\"\n",
    "        print(f\"\\nğŸ¬ å¼€å§‹ç”Ÿæˆå¹¶æ’å¯¹æ¯”è§†é¢‘...\")\n",
    "        print(f\"   ç›¸æœº: {cameras}\")\n",
    "        \n",
    "        # éªŒè¯ç›¸æœº\n",
    "        for cam in cameras:\n",
    "            if cam not in self.available_cameras:\n",
    "                raise ValueError(f\"ç›¸æœº {cam} ä¸å¯ç”¨\")\n",
    "        \n",
    "        # è·å–æ‰€æœ‰ç›¸æœºçš„å¸§ä¿¡æ¯\n",
    "        frame_getters = []\n",
    "        num_frames_list = []\n",
    "        \n",
    "        for cam in cameras:\n",
    "            num_frames, get_frame = self.get_frames(cam)\n",
    "            frame_getters.append(get_frame)\n",
    "            num_frames_list.append(num_frames)\n",
    "        \n",
    "        # ä½¿ç”¨æœ€å°å¸§æ•°\n",
    "        num_frames = min(num_frames_list)\n",
    "        print(f\"   æ€»å¸§æ•°: {num_frames}\")\n",
    "        \n",
    "        # è·å–ç¬¬ä¸€å¸§ç¡®å®šåˆ†è¾¨ç‡\n",
    "        first_frames = [getter(0) for getter in frame_getters]\n",
    "        \n",
    "        if any(f is None for f in first_frames):\n",
    "            raise RuntimeError(\"æ— æ³•è§£ç ç¬¬ä¸€å¸§\")\n",
    "        \n",
    "        # è·å–æœ€å¤§é«˜åº¦ï¼Œæ€»å®½åº¦\n",
    "        heights = [f.shape[0] for f in first_frames]\n",
    "        widths = [f.shape[1] for f in first_frames]\n",
    "        \n",
    "        max_height = max(heights)\n",
    "        total_width = sum(widths)\n",
    "        \n",
    "        print(f\"   åˆ†è¾¨ç‡: {total_width}x{max_height}\")\n",
    "        \n",
    "        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨\n",
    "        suffix = \"_with_info\" if add_info else \"\"\n",
    "        output_path = self.output_dir / f\"combined_side_by_side{suffix}.mp4\"\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*self.config['codec'])\n",
    "        writer = cv2.VideoWriter(\n",
    "            str(output_path),\n",
    "            fourcc,\n",
    "            self.config['fps'],\n",
    "            (total_width, max_height)\n",
    "        )\n",
    "        \n",
    "        if not writer.isOpened():\n",
    "            raise RuntimeError(f\"æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨\")\n",
    "        \n",
    "        # é€å¸§å†™å…¥\n",
    "        for frame_idx in tqdm(range(num_frames), desc=\"  å¤„ç†å¹¶æ’è§†é¢‘\"):\n",
    "            frames = [getter(frame_idx) for getter in frame_getters]\n",
    "            \n",
    "            # è·³è¿‡ä»»ä½•Noneå¸§\n",
    "            if any(f is None for f in frames):\n",
    "                print(f\"\\nâš ï¸  è­¦å‘Š: å¸§ {frame_idx} è§£ç å¤±è´¥ï¼Œè·³è¿‡\")\n",
    "                continue\n",
    "            \n",
    "            # æ·»åŠ ä¿¡æ¯è¦†ç›–\n",
    "            if add_info:\n",
    "                frames = [self.add_info_overlay(f, frame_idx, cam) \n",
    "                         for f, cam in zip(frames, cameras)]\n",
    "            \n",
    "            # è°ƒæ•´æ‰€æœ‰å¸§åˆ°ç›¸åŒé«˜åº¦\n",
    "            resized_frames = []\n",
    "            for frame in frames:\n",
    "                if frame.shape[0] != max_height:\n",
    "                    aspect_ratio = frame.shape[1] / frame.shape[0]\n",
    "                    new_width = int(max_height * aspect_ratio)\n",
    "                    frame = cv2.resize(frame, (new_width, max_height))\n",
    "                resized_frames.append(frame)\n",
    "            \n",
    "            # æ°´å¹³æ‹¼æ¥\n",
    "            combined = np.hstack(resized_frames)\n",
    "            \n",
    "            # è½¬æ¢RGBåˆ°BGR\n",
    "            combined_bgr = cv2.cvtColor(combined, cv2.COLOR_RGB2BGR)\n",
    "            writer.write(combined_bgr)\n",
    "        \n",
    "        writer.release()\n",
    "        print(f\"âœ… å¹¶æ’è§†é¢‘å·²ä¿å­˜: {output_path}\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def preview_frames(self, camera_name: str, frame_indices: List[int] = None):\n",
    "        \"\"\"é¢„è§ˆæŒ‡å®šç›¸æœºçš„å…³é”®å¸§\"\"\"\n",
    "        print(f\"\\nğŸ” é¢„è§ˆ {camera_name} çš„å…³é”®å¸§...\")\n",
    "        \n",
    "        num_frames, get_frame = self.get_frames(camera_name)\n",
    "        \n",
    "        # é»˜è®¤é¢„è§ˆé¦–å¸§ã€ä¸­é—´å¸§ã€æœ«å¸§\n",
    "        if frame_indices is None:\n",
    "            frame_indices = [0, num_frames // 2, num_frames - 1]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, len(frame_indices), figsize=(5 * len(frame_indices), 5))\n",
    "        if len(frame_indices) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, frame_idx in enumerate(frame_indices):\n",
    "            frame = get_frame(frame_idx)\n",
    "            \n",
    "            if frame is not None:\n",
    "                axes[idx].imshow(frame)\n",
    "                axes[idx].set_title(f\"{camera_name}\\nFrame {frame_idx}/{num_frames-1}\")\n",
    "                axes[idx].axis('off')\n",
    "            else:\n",
    "                axes[idx].text(0.5, 0.5, 'Decode Failed', \n",
    "                             ha='center', va='center', fontsize=16)\n",
    "                axes[idx].set_title(f\"Frame {frame_idx} (failed)\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# åˆ›å»ºè½¬æ¢å™¨å®ä¾‹\n",
    "converter = HDF5VideoConverter(H5_PATH, OUTPUT_DIR, VIDEO_CONFIG)\n",
    "\n",
    "print(\"\\nâœ… è½¬æ¢å™¨ç±»å·²å®šä¹‰å¹¶åˆå§‹åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. é¢„è§ˆå…³é”®å¸§\n",
    "\n",
    "åœ¨ç”Ÿæˆè§†é¢‘ä¹‹å‰ï¼Œå…ˆé¢„è§ˆå‡ å¸§ä»¥ç¡®è®¤å›¾åƒè§£ç æ­£å¸¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¢„è§ˆcamera_chestçš„å…³é”®å¸§\n",
    "converter.preview_frames('camera_chest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¢„è§ˆcamera_headçš„å…³é”®å¸§\n",
    "converter.preview_frames('camera_head')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç”Ÿæˆå•ç›¸æœºè§†é¢‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆcamera_chestè§†é¢‘ï¼ˆä¸å¸¦ä¿¡æ¯è¦†ç›–ï¼‰\n",
    "video_path_chest = converter.create_single_camera_video('camera_chest', add_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆcamera_headè§†é¢‘ï¼ˆä¸å¸¦ä¿¡æ¯è¦†ç›–ï¼‰\n",
    "video_path_head = converter.create_single_camera_video('camera_head', add_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç”Ÿæˆå¸¦ä¿¡æ¯è¦†ç›–çš„è§†é¢‘\n",
    "\n",
    "è¿™å°†åœ¨è§†é¢‘ä¸Šå åŠ å¸§å·ã€æ—¶é—´æˆ³å’Œä»»åŠ¡åç§°ç­‰ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆcamera_chestè§†é¢‘ï¼ˆå¸¦ä¿¡æ¯è¦†ç›–ï¼‰\n",
    "video_path_chest_info = converter.create_single_camera_video('camera_chest', add_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆcamera_headè§†é¢‘ï¼ˆå¸¦ä¿¡æ¯è¦†ç›–ï¼‰\n",
    "video_path_head_info = converter.create_single_camera_video('camera_head', add_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ç”Ÿæˆå¹¶æ’å¯¹æ¯”è§†é¢‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆå¹¶æ’è§†é¢‘ï¼ˆä¸å¸¦ä¿¡æ¯è¦†ç›–ï¼‰\n",
    "side_by_side_path = converter.create_side_by_side_video(\n",
    "    cameras=['camera_chest', 'camera_head'],\n",
    "    add_info=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆå¹¶æ’è§†é¢‘ï¼ˆå¸¦ä¿¡æ¯è¦†ç›–ï¼‰\n",
    "side_by_side_path_info = converter.create_side_by_side_video(\n",
    "    cameras=['camera_chest', 'camera_head'],\n",
    "    add_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ‰¹é‡å¤„ç†å¤šä¸ªHDF5æ–‡ä»¶\n",
    "\n",
    "å¦‚æœæ‚¨éœ€è¦å¤„ç†åŒä¸€ç›®å½•ä¸‹çš„å¤šä¸ªHDF5æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_h5_files(base_dir: str, pattern: str = \"**/trajectory.hdf5\", \n",
    "                          video_config: dict = None):\n",
    "    \"\"\"\n",
    "    æ‰¹é‡å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰HDF5æ–‡ä»¶\n",
    "    \n",
    "    Args:\n",
    "        base_dir: åŸºç¡€ç›®å½•\n",
    "        pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼\n",
    "        video_config: è§†é¢‘é…ç½®\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    h5_files = list(base_path.rglob(pattern))\n",
    "    \n",
    "    print(f\"ğŸ” æ‰¾åˆ° {len(h5_files)} ä¸ªHDF5æ–‡ä»¶\\n\")\n",
    "    \n",
    "    if video_config is None:\n",
    "        video_config = VIDEO_CONFIG\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, h5_file in enumerate(h5_files, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"å¤„ç† [{i}/{len(h5_files)}]: {h5_file.name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆä¸HDF5æ–‡ä»¶åŒçº§çš„videosç›®å½•ï¼‰\n",
    "            output_dir = h5_file.parent.parent / 'videos'\n",
    "            \n",
    "            # åˆ›å»ºè½¬æ¢å™¨\n",
    "            converter = HDF5VideoConverter(str(h5_file), str(output_dir), video_config)\n",
    "            \n",
    "            # ç”Ÿæˆå¹¶æ’è§†é¢‘\n",
    "            video_path = converter.create_side_by_side_video(\n",
    "                cameras=['camera_chest', 'camera_head'],\n",
    "                add_info=True\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'h5_file': str(h5_file),\n",
    "                'video_path': str(video_path),\n",
    "                'status': 'success'\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å¤„ç†å¤±è´¥: {e}\")\n",
    "            results.append({\n",
    "                'h5_file': str(h5_file),\n",
    "                'video_path': None,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # æ‰“å°æ±‡æ€»\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"æ‰¹é‡å¤„ç†å®Œæˆ\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    success_count = sum(1 for r in results if r['status'] == 'success')\n",
    "    failed_count = len(results) - success_count\n",
    "    \n",
    "    print(f\"\\nâœ… æˆåŠŸ: {success_count}\")\n",
    "    print(f\"âŒ å¤±è´¥: {failed_count}\")\n",
    "    \n",
    "    if failed_count > 0:\n",
    "        print(\"\\nå¤±è´¥åˆ—è¡¨:\")\n",
    "        for r in results:\n",
    "            if r['status'] == 'failed':\n",
    "                print(f\"  - {r['h5_file']}\")\n",
    "                print(f\"    é”™è¯¯: {r['error']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ç¤ºä¾‹ï¼šæ‰¹é‡å¤„ç†\n",
    "# base_directory = \"/projects/p32958/chengxuan/data/robomind_fail/failure_data\"\n",
    "# results = batch_process_h5_files(base_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. è§†é¢‘ä¿¡æ¯æŸ¥çœ‹\n",
    "\n",
    "æŸ¥çœ‹ç”Ÿæˆçš„è§†é¢‘ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(video_path: str) -> dict:\n",
    "    \"\"\"è·å–è§†é¢‘æ–‡ä»¶ä¿¡æ¯\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        return {\"error\": \"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶\"}\n",
    "    \n",
    "    info = {\n",
    "        'path': video_path,\n",
    "        'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "        'fps': cap.get(cv2.CAP_PROP_FPS),\n",
    "        'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "        'codec': int(cap.get(cv2.CAP_PROP_FOURCC)),\n",
    "    }\n",
    "    \n",
    "    # è®¡ç®—æ—¶é•¿\n",
    "    if info['fps'] > 0:\n",
    "        info['duration'] = info['frame_count'] / info['fps']\n",
    "    else:\n",
    "        info['duration'] = 0\n",
    "    \n",
    "    # æ–‡ä»¶å¤§å°\n",
    "    file_size = Path(video_path).stat().st_size\n",
    "    info['file_size_mb'] = file_size / 1024 / 1024\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    return info\n",
    "\n",
    "def print_video_info(video_path: str):\n",
    "    \"\"\"æ‰“å°è§†é¢‘ä¿¡æ¯\"\"\"\n",
    "    info = get_video_info(video_path)\n",
    "    \n",
    "    if 'error' in info:\n",
    "        print(f\"âŒ {info['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nğŸ“¹ è§†é¢‘ä¿¡æ¯: {Path(video_path).name}\")\n",
    "    print(f\"   åˆ†è¾¨ç‡: {info['width']}x{info['height']}\")\n",
    "    print(f\"   å¸§ç‡: {info['fps']:.2f} FPS\")\n",
    "    print(f\"   æ€»å¸§æ•°: {info['frame_count']}\")\n",
    "    print(f\"   æ—¶é•¿: {info['duration']:.2f} ç§’\")\n",
    "    print(f\"   æ–‡ä»¶å¤§å°: {info['file_size_mb']:.2f} MB\")\n",
    "\n",
    "# æŸ¥çœ‹ç”Ÿæˆçš„è§†é¢‘ä¿¡æ¯\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ç”Ÿæˆçš„è§†é¢‘ä¿¡æ¯\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# åˆ—å‡ºè¾“å‡ºç›®å½•ä¸­çš„æ‰€æœ‰è§†é¢‘\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "if output_path.exists():\n",
    "    video_files = sorted(output_path.glob(\"*.mp4\"))\n",
    "    \n",
    "    if video_files:\n",
    "        for video_file in video_files:\n",
    "            print_video_info(str(video_file))\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  è¾“å‡ºç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. å¿«é€Ÿç”Ÿæˆï¼ˆæ¨èï¼‰\n",
    "\n",
    "å¦‚æœæ‚¨åªæƒ³å¿«é€Ÿç”Ÿæˆå¸¦ä¿¡æ¯çš„å¹¶æ’è§†é¢‘ï¼Œè¿è¡Œè¿™ä¸ªcellå³å¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸€é”®ç”Ÿæˆå¸¦ä¿¡æ¯çš„å¹¶æ’è§†é¢‘\n",
    "print(\"ğŸš€ å¿«é€Ÿç”Ÿæˆæ¨¡å¼ï¼šç”Ÿæˆå¸¦ä¿¡æ¯çš„å¹¶æ’è§†é¢‘\\n\")\n",
    "\n",
    "# é‡æ–°åˆ›å»ºè½¬æ¢å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "converter = HDF5VideoConverter(H5_PATH, OUTPUT_DIR, VIDEO_CONFIG)\n",
    "\n",
    "# ç”Ÿæˆè§†é¢‘\n",
    "video_path = converter.create_side_by_side_video(\n",
    "    cameras=['camera_chest', 'camera_head'],\n",
    "    add_info=True\n",
    ")\n",
    "\n",
    "# æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯\n",
    "print_video_info(str(video_path))\n",
    "\n",
    "print(f\"\\nâœ… å®Œæˆï¼è§†é¢‘å·²ä¿å­˜åˆ°: {video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3vl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
