{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¢ç´¢ RoboMind Failure Data - HDF5 æ–‡ä»¶ç»“æ„\n",
    "\n",
    "æœ¬notebookç”¨äºåˆ†æ `/projects/p32958/chengxuan/data/robomind_fail/failure_data/135-place_cup_on_blue_bowl_with_left_hand/å¤¹å–å‰ç¢°æ’/1135137-2025_03_05_16_57_11/data/trajectory.hdf5` çš„å†…éƒ¨æ•°æ®ç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5æ–‡ä»¶è·¯å¾„\n",
    "h5_path = \"/projects/p32958/chengxuan/data/robomind_fail/failure_data/135-place_cup_on_blue_bowl_with_left_hand/å¤¹å–å‰ç¢°æ’/1135137-2025_03_05_16_57_11/data/trajectory.hdf5\"\n",
    "\n",
    "print(f\"ğŸ” åˆ†ææ–‡ä»¶: {h5_path}\")\n",
    "print(f\"æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {Path(h5_path).exists()}\")\n",
    "if Path(h5_path).exists():\n",
    "    file_size_mb = Path(h5_path).stat().st_size / 1024 / 1024\n",
    "    print(f\"æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. æ¢ç´¢HDF5æ–‡ä»¶æ•´ä½“ç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_h5_structure(path, max_depth=5):\n",
    "    \"\"\"é€’å½’æ¢ç´¢HDF5æ–‡ä»¶ç»“æ„\"\"\"\n",
    "    \n",
    "    def print_structure(name, obj, depth=0):\n",
    "        if depth > max_depth:\n",
    "            return\n",
    "        \n",
    "        indent = \"  \" * depth\n",
    "        \n",
    "        if isinstance(obj, h5py.Group):\n",
    "            print(f\"{indent}ğŸ“ {name}/ (Group)\")\n",
    "            # æ‰“å°å±æ€§\n",
    "            if obj.attrs:\n",
    "                for key, val in obj.attrs.items():\n",
    "                    print(f\"{indent}   @{key} = {val}\")\n",
    "        \n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            print(f\"{indent}ğŸ“„ {name} (Dataset)\")\n",
    "            print(f\"{indent}   Shape: {obj.shape}\")\n",
    "            print(f\"{indent}   Dtype: {obj.dtype}\")\n",
    "            \n",
    "            # å¦‚æœæ˜¯å°æ•°æ®é›†ï¼Œæ˜¾ç¤ºå‰å‡ ä¸ªå€¼\n",
    "            if obj.size < 10 and obj.size > 0:\n",
    "                try:\n",
    "                    print(f\"{indent}   Values: {obj[...]}\")\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # æ‰“å°å±æ€§\n",
    "            if obj.attrs:\n",
    "                for key, val in obj.attrs.items():\n",
    "                    print(f\"{indent}   @{key} = {val}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ” HDF5æ–‡ä»¶å®Œæ•´ç»“æ„\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    with h5py.File(path, 'r') as f:\n",
    "        # æ‰“å°æ–‡ä»¶çº§åˆ«å±æ€§\n",
    "        print(\"ğŸ“‹ æ–‡ä»¶çº§åˆ«å±æ€§:\")\n",
    "        if f.attrs:\n",
    "            for key, val in f.attrs.items():\n",
    "                print(f\"  @{key} = {val}\")\n",
    "        else:\n",
    "            print(\"  (æ— æ–‡ä»¶å±æ€§)\")\n",
    "        print()\n",
    "        \n",
    "        # æ‰“å°é¡¶å±‚keys\n",
    "        print(\"ğŸ“‚ é¡¶å±‚ç»“æ„:\")\n",
    "        print(f\"  Keys: {list(f.keys())}\")\n",
    "        print()\n",
    "        \n",
    "        # é€’å½’æ‰“å°ç»“æ„\n",
    "        print(\"ğŸ“Š è¯¦ç»†ç»“æ„:\")\n",
    "        f.visititems(print_structure)\n",
    "\n",
    "# è¿è¡Œæ¢ç´¢\n",
    "explore_h5_structure(h5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ£€æŸ¥å¸¸è§æ•°æ®è·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_common_paths(path):\n",
    "    \"\"\"æ£€æŸ¥å¸¸è§çš„æ•°æ®è·¯å¾„\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ğŸ¯ æ£€æŸ¥å¸¸è§æ•°æ®è·¯å¾„\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # å¸¸è§è·¯å¾„åˆ—è¡¨\n",
    "    paths_to_check = [\n",
    "        # è§‚æµ‹æ•°æ®\n",
    "        'observations',\n",
    "        'observations/rgb_images',\n",
    "        'observations/images',\n",
    "        'observations/depth',\n",
    "        'observations/state',\n",
    "        'observations/proprio',\n",
    "        'obs',\n",
    "        'obs/rgb_images',\n",
    "        \n",
    "        # å›¾åƒæ•°æ®\n",
    "        'rgb_images',\n",
    "        'images',\n",
    "        'camera',\n",
    "        'camera_images',\n",
    "        \n",
    "        # åŠ¨ä½œæ•°æ®\n",
    "        'actions',\n",
    "        'action',\n",
    "        \n",
    "        # çŠ¶æ€æ•°æ®\n",
    "        'states',\n",
    "        'state',\n",
    "        \n",
    "        # å¥–åŠ±/ç»ˆæ­¢\n",
    "        'rewards',\n",
    "        'reward',\n",
    "        'dones',\n",
    "        'done',\n",
    "        'terminals',\n",
    "        \n",
    "        # å…ƒæ•°æ®\n",
    "        'metadata',\n",
    "        'info',\n",
    "    ]\n",
    "    \n",
    "    with h5py.File(path, 'r') as f:\n",
    "        found_paths = []\n",
    "        missing_paths = []\n",
    "        \n",
    "        for path_str in paths_to_check:\n",
    "            if path_str in f:\n",
    "                found_paths.append(path_str)\n",
    "                obj = f[path_str]\n",
    "                \n",
    "                print(f\"âœ… {path_str}\")\n",
    "                \n",
    "                if isinstance(obj, h5py.Group):\n",
    "                    keys = list(obj.keys())\n",
    "                    print(f\"   ç±»å‹: Group\")\n",
    "                    print(f\"   å­é¡¹æ•°é‡: {len(keys)}\")\n",
    "                    if len(keys) <= 10:\n",
    "                        print(f\"   å­é¡¹åˆ—è¡¨: {keys}\")\n",
    "                    else:\n",
    "                        print(f\"   å­é¡¹åˆ—è¡¨(å‰10): {keys[:10]}...\")\n",
    "                    \n",
    "                    # å¦‚æœæ˜¯å›¾åƒç»„ï¼Œæ˜¾ç¤ºæ¯ä¸ªç›¸æœºçš„ä¿¡æ¯\n",
    "                    if 'image' in path_str.lower() or 'camera' in path_str.lower():\n",
    "                        for camera_name in keys[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª\n",
    "                            camera_data = obj[camera_name]\n",
    "                            if isinstance(camera_data, h5py.Dataset):\n",
    "                                print(f\"     - {camera_name}: shape={camera_data.shape}, dtype={camera_data.dtype}\")\n",
    "                \n",
    "                elif isinstance(obj, h5py.Dataset):\n",
    "                    print(f\"   ç±»å‹: Dataset\")\n",
    "                    print(f\"   Shape: {obj.shape}\")\n",
    "                    print(f\"   Dtype: {obj.dtype}\")\n",
    "                    \n",
    "                    # æ˜¾ç¤ºæ•°æ®èŒƒå›´\n",
    "                    if obj.size > 0 and obj.dtype.kind in ['i', 'f', 'u']:\n",
    "                        try:\n",
    "                            data_sample = obj[0] if len(obj.shape) > 0 else obj[...]\n",
    "                            print(f\"   é¦–ä¸ªå…ƒç´ : {data_sample}\")\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                # æ‰“å°å±æ€§\n",
    "                if obj.attrs:\n",
    "                    print(f\"   å±æ€§: {dict(obj.attrs)}\")\n",
    "                \n",
    "                print()\n",
    "            else:\n",
    "                missing_paths.append(path_str)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ç»Ÿè®¡: æ‰¾åˆ° {len(found_paths)}/{len(paths_to_check)} ä¸ªè·¯å¾„\")\n",
    "\n",
    "# æ£€æŸ¥å¸¸è§è·¯å¾„\n",
    "check_common_paths(h5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. åˆ†æå›¾åƒæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_data(path):\n",
    "    \"\"\"è¯¦ç»†åˆ†æå›¾åƒæ•°æ®\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ğŸ–¼ï¸ å›¾åƒæ•°æ®è¯¦ç»†åˆ†æ\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    with h5py.File(path, 'r') as f:\n",
    "        # æ£€æŸ¥æ˜¯å¦å‹ç¼©\n",
    "        is_compress = f.attrs.get('compress', False)\n",
    "        print(f\"å‹ç¼©çŠ¶æ€: {is_compress}\\n\")\n",
    "        \n",
    "        # å¯»æ‰¾å›¾åƒæ•°æ®\n",
    "        image_paths = []\n",
    "        \n",
    "        def find_images(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯å›¾åƒæ•°æ®\n",
    "                if ('image' in name.lower() or 'camera' in name.lower() or \n",
    "                    'rgb' in name.lower() or 'depth' in name.lower()):\n",
    "                    image_paths.append(name)\n",
    "        \n",
    "        f.visititems(find_images)\n",
    "        \n",
    "        if image_paths:\n",
    "            print(f\"æ‰¾åˆ° {len(image_paths)} ä¸ªå¯èƒ½çš„å›¾åƒæ•°æ®é›†:\\n\")\n",
    "            \n",
    "            for img_path in image_paths:\n",
    "                img_data = f[img_path]\n",
    "                print(f\"ğŸ“· {img_path}\")\n",
    "                print(f\"   Shape: {img_data.shape}\")\n",
    "                print(f\"   Dtype: {img_data.dtype}\")\n",
    "                print(f\"   Size: {img_data.size} elements\")\n",
    "                print(f\"   Memory: {img_data.nbytes / 1024 / 1024:.2f} MB\")\n",
    "                \n",
    "                # åˆ†æshapeå«ä¹‰\n",
    "                if len(img_data.shape) >= 2:\n",
    "                    print(f\"   å¯èƒ½çš„è§£é‡Š:\")\n",
    "                    if len(img_data.shape) == 1:\n",
    "                        print(f\"     - å‹ç¼©å›¾åƒæ•°æ® (éœ€è¦è§£ç )\")\n",
    "                    elif len(img_data.shape) == 2:\n",
    "                        print(f\"     - {img_data.shape[0]} å¸§å‹ç¼©å›¾åƒ\")\n",
    "                        print(f\"     - æˆ– {img_data.shape[0]}x{img_data.shape[1]} ç°åº¦å›¾åƒ\")\n",
    "                    elif len(img_data.shape) == 3:\n",
    "                        if img_data.shape[-1] in [1, 3, 4]:\n",
    "                            print(f\"     - å•å¸§å›¾åƒ: {img_data.shape[0]}x{img_data.shape[1]}, {img_data.shape[2]} é€šé“\")\n",
    "                        else:\n",
    "                            print(f\"     - {img_data.shape[0]} å¸§, {img_data.shape[1]}x{img_data.shape[2]} å›¾åƒ\")\n",
    "                    elif len(img_data.shape) == 4:\n",
    "                        print(f\"     - {img_data.shape[0]} å¸§\")\n",
    "                        print(f\"     - åˆ†è¾¨ç‡: {img_data.shape[1]}x{img_data.shape[2]}\")\n",
    "                        print(f\"     - é€šé“æ•°: {img_data.shape[3]}\")\n",
    "                \n",
    "                print()\n",
    "        else:\n",
    "            print(\"âŒ æœªæ‰¾åˆ°å›¾åƒæ•°æ®\")\n",
    "\n",
    "# åˆ†æå›¾åƒæ•°æ®\n",
    "analyze_image_data(h5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. åˆ†æåŠ¨ä½œå’ŒçŠ¶æ€æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_action_state_data(path):\n",
    "    \"\"\"åˆ†æåŠ¨ä½œå’ŒçŠ¶æ€æ•°æ®\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ğŸ® åŠ¨ä½œå’ŒçŠ¶æ€æ•°æ®åˆ†æ\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    with h5py.File(path, 'r') as f:\n",
    "        # æŸ¥æ‰¾åŠ¨ä½œæ•°æ®\n",
    "        action_paths = ['actions', 'action', 'act']\n",
    "        state_paths = ['states', 'state', 'observations/state', 'observations/proprio']\n",
    "        \n",
    "        print(\"ğŸ¯ åŠ¨ä½œæ•°æ®:\")\n",
    "        found_action = False\n",
    "        for action_path in action_paths:\n",
    "            if action_path in f:\n",
    "                found_action = True\n",
    "                action_data = f[action_path]\n",
    "                print(f\"\\n  è·¯å¾„: {action_path}\")\n",
    "                print(f\"  Shape: {action_data.shape}\")\n",
    "                print(f\"  Dtype: {action_data.dtype}\")\n",
    "                \n",
    "                if len(action_data.shape) == 2:\n",
    "                    print(f\"  æ—¶é—´æ­¥æ•°: {action_data.shape[0]}\")\n",
    "                    print(f\"  åŠ¨ä½œç»´åº¦: {action_data.shape[1]}\")\n",
    "                    \n",
    "                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯\n",
    "                    if action_data.dtype.kind in ['f', 'i', 'u']:\n",
    "                        print(f\"  æ•°å€¼èŒƒå›´:\")\n",
    "                        print(f\"    Min: {np.min(action_data[...], axis=0)}\")\n",
    "                        print(f\"    Max: {np.max(action_data[...], axis=0)}\")\n",
    "                        print(f\"    Mean: {np.mean(action_data[...], axis=0)}\")\n",
    "                        print(f\"  å‰3ä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œ:\")\n",
    "                        print(action_data[:3])\n",
    "        \n",
    "        if not found_action:\n",
    "            print(\"  âŒ æœªæ‰¾åˆ°åŠ¨ä½œæ•°æ®\\n\")\n",
    "        \n",
    "        print(\"\\nğŸ“Š çŠ¶æ€æ•°æ®:\")\n",
    "        found_state = False\n",
    "        for state_path in state_paths:\n",
    "            if state_path in f:\n",
    "                found_state = True\n",
    "                state_data = f[state_path]\n",
    "                print(f\"\\n  è·¯å¾„: {state_path}\")\n",
    "                \n",
    "                if isinstance(state_data, h5py.Group):\n",
    "                    print(f\"  ç±»å‹: Group\")\n",
    "                    print(f\"  åŒ…å«çš„çŠ¶æ€: {list(state_data.keys())}\")\n",
    "                    for key in state_data.keys():\n",
    "                        sub_data = state_data[key]\n",
    "                        if isinstance(sub_data, h5py.Dataset):\n",
    "                            print(f\"    - {key}: shape={sub_data.shape}, dtype={sub_data.dtype}\")\n",
    "                else:\n",
    "                    print(f\"  Shape: {state_data.shape}\")\n",
    "                    print(f\"  Dtype: {state_data.dtype}\")\n",
    "                    \n",
    "                    if len(state_data.shape) == 2:\n",
    "                        print(f\"  æ—¶é—´æ­¥æ•°: {state_data.shape[0]}\")\n",
    "                        print(f\"  çŠ¶æ€ç»´åº¦: {state_data.shape[1]}\")\n",
    "                        print(f\"  å‰3ä¸ªæ—¶é—´æ­¥çš„çŠ¶æ€:\")\n",
    "                        print(state_data[:3])\n",
    "        \n",
    "        if not found_state:\n",
    "            print(\"  âŒ æœªæ‰¾åˆ°çŠ¶æ€æ•°æ®\")\n",
    "\n",
    "# åˆ†æåŠ¨ä½œå’ŒçŠ¶æ€æ•°æ®\n",
    "analyze_action_state_data(h5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æå–å¹¶å¯è§†åŒ–ç¤ºä¾‹å›¾åƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(compressed_image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"è§£ç å‹ç¼©çš„å›¾åƒæ•°æ®\"\"\"\n",
    "    if compressed_image is None:\n",
    "        return None\n",
    "    \n",
    "    # å¦‚æœæ˜¯å•ä¸ªå›¾åƒ\n",
    "    if len(compressed_image.shape) == 1:\n",
    "        rgb = cv2.imdecode(compressed_image, cv2.IMREAD_COLOR)\n",
    "        if rgb is None:\n",
    "            # å°è¯•ç›´æ¥è§£æä¸ºæ•°ç»„\n",
    "            rgb = np.frombuffer(compressed_image, dtype=np.uint8)\n",
    "            # æ ¹æ®å¤§å°åˆ¤æ–­å›¾åƒå°ºå¯¸\n",
    "            if rgb.size == 2764800:  # 720 * 1280 * 3\n",
    "                rgb = rgb.reshape(720, 1280, 3)\n",
    "            elif rgb.size == 921600:  # 480 * 640 * 3\n",
    "                rgb = rgb.reshape(480, 640, 3)\n",
    "            elif rgb.size == 307200:  # 480 * 640\n",
    "                rgb = rgb.reshape(480, 640)\n",
    "        if rgb is not None and len(rgb.shape) == 3:\n",
    "            rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        return rgb\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def visualize_images(path, num_frames=3):\n",
    "    \"\"\"æå–å¹¶å¯è§†åŒ–å›¾åƒ\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ğŸ¨ å›¾åƒå¯è§†åŒ–\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    with h5py.File(path, 'r') as f:\n",
    "        # æŸ¥æ‰¾å›¾åƒæ•°æ®\n",
    "        image_groups = []\n",
    "        \n",
    "        # æ£€æŸ¥å¸¸è§è·¯å¾„\n",
    "        if 'observations/rgb_images' in f:\n",
    "            image_groups.append(('observations/rgb_images', f['observations/rgb_images']))\n",
    "        elif 'rgb_images' in f:\n",
    "            image_groups.append(('rgb_images', f['rgb_images']))\n",
    "        elif 'images' in f:\n",
    "            image_groups.append(('images', f['images']))\n",
    "        \n",
    "        if not image_groups:\n",
    "            print(\"âŒ æœªæ‰¾åˆ°å¯è§†åŒ–çš„å›¾åƒæ•°æ®\")\n",
    "            return\n",
    "        \n",
    "        is_compress = f.attrs.get('compress', True)\n",
    "        \n",
    "        for group_name, image_group in image_groups:\n",
    "            print(f\"\\nğŸ“· å¯è§†åŒ–: {group_name}\")\n",
    "            \n",
    "            if isinstance(image_group, h5py.Group):\n",
    "                cameras = list(image_group.keys())\n",
    "                print(f\"   æ‰¾åˆ° {len(cameras)} ä¸ªç›¸æœº: {cameras}\\n\")\n",
    "                \n",
    "                # ä¸ºæ¯ä¸ªç›¸æœºå¯è§†åŒ–\n",
    "                for camera_name in cameras[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªç›¸æœº\n",
    "                    camera_data = image_group[camera_name]\n",
    "                    total_frames = camera_data.shape[0]\n",
    "                    \n",
    "                    print(f\"   ç›¸æœº: {camera_name}, æ€»å¸§æ•°: {total_frames}\")\n",
    "                    \n",
    "                    # é€‰æ‹©è¦æ˜¾ç¤ºçš„å¸§ç´¢å¼•\n",
    "                    if total_frames <= num_frames:\n",
    "                        frame_indices = list(range(total_frames))\n",
    "                    else:\n",
    "                        # å‡åŒ€é‡‡æ ·\n",
    "                        frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)\n",
    "                    \n",
    "                    # åˆ›å»ºå›¾åƒæ˜¾ç¤º\n",
    "                    fig, axes = plt.subplots(1, len(frame_indices), figsize=(5*len(frame_indices), 5))\n",
    "                    if len(frame_indices) == 1:\n",
    "                        axes = [axes]\n",
    "                    \n",
    "                    for idx, frame_idx in enumerate(frame_indices):\n",
    "                        # è¯»å–å›¾åƒ\n",
    "                        if is_compress:\n",
    "                            img = decode_image(camera_data[frame_idx])\n",
    "                        else:\n",
    "                            img = camera_data[frame_idx]\n",
    "                        \n",
    "                        if img is not None:\n",
    "                            axes[idx].imshow(img)\n",
    "                            axes[idx].set_title(f\"{camera_name}\\nFrame {frame_idx}/{total_frames-1}\")\n",
    "                            axes[idx].axis('off')\n",
    "                        else:\n",
    "                            axes[idx].text(0.5, 0.5, 'Failed to decode', \n",
    "                                         ha='center', va='center')\n",
    "                            axes[idx].set_title(f\"Frame {frame_idx} (decode failed)\")\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "            \n",
    "            elif isinstance(image_group, h5py.Dataset):\n",
    "                # ç›´æ¥æ˜¯æ•°æ®é›†\n",
    "                total_frames = image_group.shape[0]\n",
    "                print(f\"   æ€»å¸§æ•°: {total_frames}\\n\")\n",
    "                \n",
    "                # é€‰æ‹©è¦æ˜¾ç¤ºçš„å¸§ç´¢å¼•\n",
    "                if total_frames <= num_frames:\n",
    "                    frame_indices = list(range(total_frames))\n",
    "                else:\n",
    "                    frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)\n",
    "                \n",
    "                # åˆ›å»ºå›¾åƒæ˜¾ç¤º\n",
    "                fig, axes = plt.subplots(1, len(frame_indices), figsize=(5*len(frame_indices), 5))\n",
    "                if len(frame_indices) == 1:\n",
    "                    axes = [axes]\n",
    "                \n",
    "                for idx, frame_idx in enumerate(frame_indices):\n",
    "                    if is_compress:\n",
    "                        img = decode_image(image_group[frame_idx])\n",
    "                    else:\n",
    "                        img = image_group[frame_idx]\n",
    "                    \n",
    "                    if img is not None:\n",
    "                        axes[idx].imshow(img)\n",
    "                        axes[idx].set_title(f\"Frame {frame_idx}/{total_frames-1}\")\n",
    "                        axes[idx].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "# å¯è§†åŒ–å›¾åƒ\n",
    "visualize_images(h5_path, num_frames=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç”Ÿæˆå®Œæ•´æ•°æ®æ‘˜è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(path):\n",
    "    \"\"\"ç”Ÿæˆæ•°æ®é›†çš„å®Œæ•´æ‘˜è¦\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ğŸ“‹ å®Œæ•´æ•°æ®æ‘˜è¦\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    with h5py.File(path, 'r') as f:\n",
    "        summary = {\n",
    "            'file_attrs': dict(f.attrs),\n",
    "            'top_level_keys': list(f.keys()),\n",
    "            'data_types': {}\n",
    "        }\n",
    "        \n",
    "        # æ”¶é›†æ‰€æœ‰æ•°æ®é›†ä¿¡æ¯\n",
    "        def collect_info(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                summary['data_types'][name] = {\n",
    "                    'shape': obj.shape,\n",
    "                    'dtype': str(obj.dtype),\n",
    "                    'size_mb': obj.nbytes / 1024 / 1024\n",
    "                }\n",
    "        \n",
    "        f.visititems(collect_info)\n",
    "        \n",
    "        # æ‰“å°æ‘˜è¦\n",
    "        print(\"ğŸ“ æ–‡ä»¶å±æ€§:\")\n",
    "        for key, val in summary['file_attrs'].items():\n",
    "            print(f\"  {key}: {val}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‚ é¡¶å±‚ç»“æ„: {summary['top_level_keys']}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ (å…± {len(summary['data_types'])} ä¸ª):\")\n",
    "        print(f\"\\n{'è·¯å¾„':<50} {'Shape':<25} {'ç±»å‹':<15} {'å¤§å°(MB)':>10}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        total_size = 0\n",
    "        for name, info in sorted(summary['data_types'].items()):\n",
    "            shape_str = str(info['shape'])\n",
    "            print(f\"{name:<50} {shape_str:<25} {info['dtype']:<15} {info['size_mb']:>10.2f}\")\n",
    "            total_size += info['size_mb']\n",
    "        \n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'æ€»è®¡':<90} {total_size:>10.2f}\")\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# ç”Ÿæˆæ‘˜è¦\n",
    "summary = generate_summary(h5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å¯¼å‡ºæ•°æ®æ‘˜è¦åˆ°JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# å¯¼å‡ºæ‘˜è¦åˆ°JSONæ–‡ä»¶\n",
    "output_json = Path(h5_path).parent / \"trajectory_summary.json\"\n",
    "\n",
    "# è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "summary_serializable = json.loads(\n",
    "    json.dumps(summary, default=convert_to_serializable)\n",
    ")\n",
    "\n",
    "with open(output_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_serializable, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nâœ… æ‘˜è¦å·²ä¿å­˜åˆ°: {output_json}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
