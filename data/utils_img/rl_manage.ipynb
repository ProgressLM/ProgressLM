{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cb8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Data Source: h5_agilex_3rgb\n",
      "  â–¶ visual_steps:\n",
      "     Count: 7622\n",
      "     Min: 4\n",
      "     Max: 11\n",
      "     Mean: 7.63\n",
      "     Median: 8.00\n",
      "     Distribution (step count frequencies): {9: 1412, 7: 1895, 10: 540, 8: 2242, 5: 564, 6: 873, 11: 61, 4: 35}\n",
      "  â–¶ text_steps:\n",
      "     Count: 2226\n",
      "     Min: 3\n",
      "     Max: 10\n",
      "     Mean: 6.72\n",
      "     Median: 7.00\n",
      "     Distribution (step count frequencies): {7: 624, 6: 536, 5: 262, 8: 423, 9: 172, 4: 147, 10: 50, 3: 12}\n",
      "\n",
      "ğŸ“ Data Source: h5_ur_1rgb\n",
      "  â–¶ visual_steps:\n",
      "     Count: 9595\n",
      "     Min: 1\n",
      "     Max: 9\n",
      "     Mean: 3.21\n",
      "     Median: 3.00\n",
      "     Distribution (step count frequencies): {3: 5059, 1: 94, 4: 1306, 5: 797, 2: 2000, 6: 223, 7: 40, 9: 52, 8: 24}\n",
      "\n",
      "ğŸ“ Data Source: h5_franka_3rgb\n",
      "  â–¶ visual_steps:\n",
      "     Count: 7596\n",
      "     Min: 2\n",
      "     Max: 9\n",
      "     Mean: 4.66\n",
      "     Median: 5.00\n",
      "     Distribution (step count frequencies): {4: 3057, 5: 3865, 6: 186, 3: 192, 7: 141, 9: 26, 8: 114, 2: 15}\n",
      "  â–¶ text_steps:\n",
      "     Count: 2541\n",
      "     Min: 3\n",
      "     Max: 9\n",
      "     Mean: 4.66\n",
      "     Median: 5.00\n",
      "     Distribution (step count frequencies): {5: 1309, 4: 1024, 6: 57, 3: 61, 7: 46, 8: 37, 9: 7}\n",
      "\n",
      "ğŸ“ Data Source: h5_tienkung_xsens_1rgb\n",
      "  â–¶ visual_steps:\n",
      "     Count: 7794\n",
      "     Min: 3\n",
      "     Max: 10\n",
      "     Mean: 6.04\n",
      "     Median: 6.00\n",
      "     Distribution (step count frequencies): {6: 1999, 10: 56, 4: 959, 5: 1698, 8: 647, 7: 1972, 9: 310, 3: 153}\n",
      "  â–¶ text_steps:\n",
      "     Count: 2626\n",
      "     Min: 3\n",
      "     Max: 10\n",
      "     Mean: 6.06\n",
      "     Median: 6.00\n",
      "     Distribution (step count frequencies): {8: 273, 5: 534, 4: 326, 6: 704, 7: 652, 9: 84, 3: 46, 10: 7}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "file_path = \"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_sampled_4to8.jsonl\"\n",
    "\n",
    "# åˆå§‹åŒ–ç»Ÿè®¡ç»“æ„\n",
    "stats = defaultdict(lambda: {\"visual_steps\": [], \"text_steps\": []})\n",
    "\n",
    "# è¯»å–æ•°æ®\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            item = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        ds = item.get(\"data_source\", \"unknown\")\n",
    "        steps = item.get(\"total_steps\")\n",
    "\n",
    "        # æœ‰äº› total_steps æ˜¯å­—ç¬¦ä¸²ï¼Œç»Ÿä¸€è½¬æ¢ä¸ºæ•´æ•°\n",
    "        if isinstance(steps, str):\n",
    "            try:\n",
    "                steps = int(steps)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        if \"visual_demo\" in item:\n",
    "            stats[ds][\"visual_steps\"].append(steps)\n",
    "        if \"text_demo\" in item:\n",
    "            stats[ds][\"text_steps\"].append(steps)\n",
    "\n",
    "# æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "for ds, data in stats.items():\n",
    "    print(f\"\\nğŸ“ Data Source: {ds}\")\n",
    "    for key, arr in data.items():\n",
    "        if not arr:\n",
    "            continue\n",
    "        arr_np = np.array(arr)\n",
    "        print(f\"  â–¶ {key}:\")\n",
    "        print(f\"     Count: {len(arr)}\")\n",
    "        print(f\"     Min: {arr_np.min()}\")\n",
    "        print(f\"     Max: {arr_np.max()}\")\n",
    "        print(f\"     Mean: {arr_np.mean():.2f}\")\n",
    "        print(f\"     Median: {np.median(arr_np):.2f}\")\n",
    "        print(f\"     Distribution (step count frequencies): {dict(Counter(arr))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c85acd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def analyze_step_distribution_vt(jsonl_path, by_source=False):\n",
    "    \"\"\"\n",
    "    åˆ†åˆ«ç»Ÿè®¡ visual_demo å’Œ text_demo çš„ total_steps åˆ†å¸ƒ\n",
    "    å‚æ•°:\n",
    "        jsonl_path (str): JSONL æ–‡ä»¶è·¯å¾„\n",
    "        by_source (bool): æ˜¯å¦æŒ‰ data_source åˆ†ç»„ç»Ÿè®¡\n",
    "    \"\"\"\n",
    "\n",
    "    stats = {\n",
    "        \"visual\": Counter(),\n",
    "        \"text\": Counter(),\n",
    "    }\n",
    "    counts = {\"visual\": 0, \"text\": 0}\n",
    "    stats_by_source = defaultdict(lambda: {\"visual\": Counter(), \"text\": Counter()})\n",
    "\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "            steps = item.get(\"total_steps\")\n",
    "            if isinstance(steps, str):\n",
    "                try:\n",
    "                    steps = int(steps)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "            ds = item.get(\"data_source\", \"unknown\")\n",
    "\n",
    "            # åˆ†åˆ«è®¡æ•°\n",
    "            if \"visual_demo\" in item:\n",
    "                stats[\"visual\"][steps] += 1\n",
    "                counts[\"visual\"] += 1\n",
    "                if by_source:\n",
    "                    stats_by_source[ds][\"visual\"][steps] += 1\n",
    "            if \"text_demo\" in item:\n",
    "                stats[\"text\"][steps] += 1\n",
    "                counts[\"text\"] += 1\n",
    "                if by_source:\n",
    "                    stats_by_source[ds][\"text\"][steps] += 1\n",
    "\n",
    "    # è¾“å‡ºæ±‡æ€»\n",
    "    print(f\"ğŸ“Š æ–‡ä»¶: {jsonl_path}\\n\")\n",
    "\n",
    "    for mode in [\"visual\", \"text\"]:\n",
    "        total = counts[mode]\n",
    "        print(f\"=== ğŸ§® {mode.upper()} DEMO åˆ†å¸ƒ (å…± {total} æ¡) ===\")\n",
    "        for step, count in sorted(stats[mode].items()):\n",
    "            pct = count / total * 100 if total > 0 else 0\n",
    "            print(f\"steps={step:<4} â†’ {count:>6} æ ·æœ¬ ({pct:5.2f}%)\")\n",
    "        print()\n",
    "\n",
    "    if by_source:\n",
    "        print(\"=== ğŸ“ æŒ‰ data_source ç»†åˆ† ===\")\n",
    "        for ds, data in stats_by_source.items():\n",
    "            print(f\"\\nâ¡ï¸ {ds}\")\n",
    "            for mode in [\"visual\", \"text\"]:\n",
    "                total = sum(data[mode].values())\n",
    "                if total == 0:\n",
    "                    continue\n",
    "                print(f\"  â–¸ {mode.upper()} ({total} æ¡):\")\n",
    "                for step, count in sorted(data[mode].items()):\n",
    "                    pct = count / total * 100\n",
    "                    print(f\"     steps={step:<4} â†’ {count:>5} æ ·æœ¬ ({pct:5.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff898d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æ–‡ä»¶: /projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_all.jsonl\n",
      "\n",
      "=== ğŸ§® VISUAL DEMO åˆ†å¸ƒ (å…± 98733 æ¡) ===\n",
      "steps=1    â†’    165 æ ·æœ¬ ( 0.17%)\n",
      "steps=2    â†’   3516 æ ·æœ¬ ( 3.56%)\n",
      "steps=3    â†’  12492 æ ·æœ¬ (12.65%)\n",
      "steps=4    â†’  14064 æ ·æœ¬ (14.24%)\n",
      "steps=5    â†’  17205 æ ·æœ¬ (17.43%)\n",
      "steps=6    â†’   8082 æ ·æœ¬ ( 8.19%)\n",
      "steps=7    â†’  10836 æ ·æœ¬ (10.98%)\n",
      "steps=8    â†’  10584 æ ·æœ¬ (10.72%)\n",
      "steps=9    â†’   7884 æ ·æœ¬ ( 7.99%)\n",
      "steps=10   â†’   6870 æ ·æœ¬ ( 6.96%)\n",
      "steps=11   â†’   3465 æ ·æœ¬ ( 3.51%)\n",
      "steps=12   â†’   1296 æ ·æœ¬ ( 1.31%)\n",
      "steps=13   â†’    741 æ ·æœ¬ ( 0.75%)\n",
      "steps=14   â†’    420 æ ·æœ¬ ( 0.43%)\n",
      "steps=15   â†’    675 æ ·æœ¬ ( 0.68%)\n",
      "steps=16   â†’    336 æ ·æœ¬ ( 0.34%)\n",
      "steps=17   â†’    102 æ ·æœ¬ ( 0.10%)\n",
      "\n",
      "=== ğŸ§® TEXT DEMO åˆ†å¸ƒ (å…± 25490 æ¡) ===\n",
      "steps=3    â†’   1158 æ ·æœ¬ ( 4.54%)\n",
      "steps=4    â†’   4340 æ ·æœ¬ (17.03%)\n",
      "steps=5    â†’   5555 æ ·æœ¬ (21.79%)\n",
      "steps=6    â†’   3516 æ ·æœ¬ (13.79%)\n",
      "steps=7    â†’   3451 æ ·æœ¬ (13.54%)\n",
      "steps=8    â†’   2848 æ ·æœ¬ (11.17%)\n",
      "steps=9    â†’   2394 æ ·æœ¬ ( 9.39%)\n",
      "steps=10   â†’   1100 æ ·æœ¬ ( 4.32%)\n",
      "steps=11   â†’    363 æ ·æœ¬ ( 1.42%)\n",
      "steps=12   â†’    276 æ ·æœ¬ ( 1.08%)\n",
      "steps=13   â†’    143 æ ·æœ¬ ( 0.56%)\n",
      "steps=14   â†’    224 æ ·æœ¬ ( 0.88%)\n",
      "steps=15   â†’     90 æ ·æœ¬ ( 0.35%)\n",
      "steps=16   â†’     32 æ ·æœ¬ ( 0.13%)\n",
      "\n",
      "=== ğŸ“ æŒ‰ data_source ç»†åˆ† ===\n",
      "\n",
      "â¡ï¸ h5_agilex_3rgb\n",
      "  â–¸ VISUAL (41310 æ¡):\n",
      "     steps=3    â†’     9 æ ·æœ¬ ( 0.02%)\n",
      "     steps=4    â†’   504 æ ·æœ¬ ( 1.22%)\n",
      "     steps=5    â†’  2205 æ ·æœ¬ ( 5.34%)\n",
      "     steps=6    â†’  3366 æ ·æœ¬ ( 8.15%)\n",
      "     steps=7    â†’  7182 æ ·æœ¬ (17.39%)\n",
      "     steps=8    â†’  7920 æ ·æœ¬ (19.17%)\n",
      "     steps=9    â†’  6561 æ ·æœ¬ (15.88%)\n",
      "     steps=10   â†’  6750 æ ·æœ¬ (16.34%)\n",
      "     steps=11   â†’  3399 æ ·æœ¬ ( 8.23%)\n",
      "     steps=12   â†’  1188 æ ·æœ¬ ( 2.88%)\n",
      "     steps=13   â†’   741 æ ·æœ¬ ( 1.79%)\n",
      "     steps=14   â†’   420 æ ·æœ¬ ( 1.02%)\n",
      "     steps=15   â†’   675 æ ·æœ¬ ( 1.63%)\n",
      "     steps=16   â†’   288 æ ·æœ¬ ( 0.70%)\n",
      "     steps=17   â†’   102 æ ·æœ¬ ( 0.25%)\n",
      "  â–¸ TEXT (12064 æ¡):\n",
      "     steps=3    â†’   129 æ ·æœ¬ ( 1.07%)\n",
      "     steps=4    â†’   616 æ ·æœ¬ ( 5.11%)\n",
      "     steps=5    â†’   920 æ ·æœ¬ ( 7.63%)\n",
      "     steps=6    â†’  2040 æ ·æœ¬ (16.91%)\n",
      "     steps=7    â†’  2247 æ ·æœ¬ (18.63%)\n",
      "     steps=8    â†’  1968 æ ·æœ¬ (16.31%)\n",
      "     steps=9    â†’  2007 æ ·æœ¬ (16.64%)\n",
      "     steps=10   â†’  1080 æ ·æœ¬ ( 8.95%)\n",
      "     steps=11   â†’   341 æ ·æœ¬ ( 2.83%)\n",
      "     steps=12   â†’   240 æ ·æœ¬ ( 1.99%)\n",
      "     steps=13   â†’   130 æ ·æœ¬ ( 1.08%)\n",
      "     steps=14   â†’   224 æ ·æœ¬ ( 1.86%)\n",
      "     steps=15   â†’    90 æ ·æœ¬ ( 0.75%)\n",
      "     steps=16   â†’    32 æ ·æœ¬ ( 0.27%)\n",
      "\n",
      "â¡ï¸ h5_tienkung_xsens_1rgb\n",
      "  â–¸ VISUAL (10359 æ¡):\n",
      "     steps=2    â†’    30 æ ·æœ¬ ( 0.29%)\n",
      "     steps=3    â†’   477 æ ·æœ¬ ( 4.60%)\n",
      "     steps=4    â†’  1056 æ ·æœ¬ (10.19%)\n",
      "     steps=5    â†’  2010 æ ·æœ¬ (19.40%)\n",
      "     steps=6    â†’  3006 æ ·æœ¬ (29.02%)\n",
      "     steps=7    â†’  2184 æ ·æœ¬ (21.08%)\n",
      "     steps=8    â†’  1152 æ ·æœ¬ (11.12%)\n",
      "     steps=9    â†’   351 æ ·æœ¬ ( 3.39%)\n",
      "     steps=10   â†’    60 æ ·æœ¬ ( 0.58%)\n",
      "     steps=11   â†’    33 æ ·æœ¬ ( 0.32%)\n",
      "  â–¸ TEXT (3436 æ¡):\n",
      "     steps=3    â†’   141 æ ·æœ¬ ( 4.10%)\n",
      "     steps=4    â†’   360 æ ·æœ¬ (10.48%)\n",
      "     steps=5    â†’   670 æ ·æœ¬ (19.50%)\n",
      "     steps=6    â†’  1026 æ ·æœ¬ (29.86%)\n",
      "     steps=7    â†’   735 æ ·æœ¬ (21.39%)\n",
      "     steps=8    â†’   384 æ ·æœ¬ (11.18%)\n",
      "     steps=9    â†’    99 æ ·æœ¬ ( 2.88%)\n",
      "     steps=10   â†’    10 æ ·æœ¬ ( 0.29%)\n",
      "     steps=11   â†’    11 æ ·æœ¬ ( 0.32%)\n",
      "\n",
      "â¡ï¸ h5_franka_3rgb\n",
      "  â–¸ VISUAL (30168 æ¡):\n",
      "     steps=1    â†’     3 æ ·æœ¬ ( 0.01%)\n",
      "     steps=2    â†’   162 æ ·æœ¬ ( 0.54%)\n",
      "     steps=3    â†’  2727 æ ·æœ¬ ( 9.04%)\n",
      "     steps=4    â†’  9960 æ ·æœ¬ (33.02%)\n",
      "     steps=5    â†’ 11925 æ ·æœ¬ (39.53%)\n",
      "     steps=6    â†’  1350 æ ·æœ¬ ( 4.47%)\n",
      "     steps=7    â†’  1386 æ ·æœ¬ ( 4.59%)\n",
      "     steps=8    â†’  1488 æ ·æœ¬ ( 4.93%)\n",
      "     steps=9    â†’   918 æ ·æœ¬ ( 3.04%)\n",
      "     steps=10   â†’    60 æ ·æœ¬ ( 0.20%)\n",
      "     steps=11   â†’    33 æ ·æœ¬ ( 0.11%)\n",
      "     steps=12   â†’   108 æ ·æœ¬ ( 0.36%)\n",
      "     steps=16   â†’    48 æ ·æœ¬ ( 0.16%)\n",
      "  â–¸ TEXT (9990 æ¡):\n",
      "     steps=3    â†’   888 æ ·æœ¬ ( 8.89%)\n",
      "     steps=4    â†’  3364 æ ·æœ¬ (33.67%)\n",
      "     steps=5    â†’  3965 æ ·æœ¬ (39.69%)\n",
      "     steps=6    â†’   450 æ ·æœ¬ ( 4.50%)\n",
      "     steps=7    â†’   469 æ ·æœ¬ ( 4.69%)\n",
      "     steps=8    â†’   496 æ ·æœ¬ ( 4.96%)\n",
      "     steps=9    â†’   288 æ ·æœ¬ ( 2.88%)\n",
      "     steps=10   â†’    10 æ ·æœ¬ ( 0.10%)\n",
      "     steps=11   â†’    11 æ ·æœ¬ ( 0.11%)\n",
      "     steps=12   â†’    36 æ ·æœ¬ ( 0.36%)\n",
      "     steps=13   â†’    13 æ ·æœ¬ ( 0.13%)\n",
      "\n",
      "â¡ï¸ h5_ur_1rgb\n",
      "  â–¸ VISUAL (16896 æ¡):\n",
      "     steps=1    â†’   162 æ ·æœ¬ ( 0.96%)\n",
      "     steps=2    â†’  3324 æ ·æœ¬ (19.67%)\n",
      "     steps=3    â†’  9279 æ ·æœ¬ (54.92%)\n",
      "     steps=4    â†’  2544 æ ·æœ¬ (15.06%)\n",
      "     steps=5    â†’  1065 æ ·æœ¬ ( 6.30%)\n",
      "     steps=6    â†’   360 æ ·æœ¬ ( 2.13%)\n",
      "     steps=7    â†’    84 æ ·æœ¬ ( 0.50%)\n",
      "     steps=8    â†’    24 æ ·æœ¬ ( 0.14%)\n",
      "     steps=9    â†’    54 æ ·æœ¬ ( 0.32%)\n"
     ]
    }
   ],
   "source": [
    "analyze_step_distribution_vt(\"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_all.jsonl\", by_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "856753f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š === å…¨å±€ç»Ÿè®¡ ===\n",
      "  æœ‰ visual_demo çš„æ ·æœ¬: 98733\n",
      "  æœ‰ text_demo çš„æ ·æœ¬:   25490\n",
      "  åŒæ—¶æœ‰ visual å’Œ text:  0\n",
      "\n",
      "ğŸ“ === æŒ‰ data_source åˆ†ç±»ç»Ÿè®¡ ===\n",
      "  h5_agilex_3rgb            â†’ visual=41310  text=12064  both=0     \n",
      "  h5_franka_3rgb            â†’ visual=30168  text=9990   both=0     \n",
      "  h5_tienkung_xsens_1rgb    â†’ visual=10359  text=3436   both=0     \n",
      "  h5_ur_1rgb                â†’ visual=16896  text=0      both=0     \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "file_path = \"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_all.jsonl\"\n",
    "\n",
    "# åˆå§‹åŒ–ç»Ÿè®¡\n",
    "visual_total = 0\n",
    "text_total = 0\n",
    "both_total = 0\n",
    "\n",
    "visual_by_source = defaultdict(int)\n",
    "text_by_source = defaultdict(int)\n",
    "both_by_source = defaultdict(int)\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            item = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        ds = item.get(\"data_source\", \"unknown\")\n",
    "        has_visual = \"visual_demo\" in item\n",
    "        has_text = \"text_demo\" in item\n",
    "\n",
    "        if has_visual:\n",
    "            visual_total += 1\n",
    "            visual_by_source[ds] += 1\n",
    "        if has_text:\n",
    "            text_total += 1\n",
    "            text_by_source[ds] += 1\n",
    "        if has_visual and has_text:\n",
    "            both_total += 1\n",
    "            both_by_source[ds] += 1\n",
    "\n",
    "# ===== è¾“å‡ºç»“æœ =====\n",
    "print(\"ğŸ“Š === å…¨å±€ç»Ÿè®¡ ===\")\n",
    "print(f\"  æœ‰ visual_demo çš„æ ·æœ¬: {visual_total}\")\n",
    "print(f\"  æœ‰ text_demo çš„æ ·æœ¬:   {text_total}\")\n",
    "print(f\"  åŒæ—¶æœ‰ visual å’Œ text:  {both_total}\")\n",
    "\n",
    "print(\"\\nğŸ“ === æŒ‰ data_source åˆ†ç±»ç»Ÿè®¡ ===\")\n",
    "sources = sorted(set(list(visual_by_source.keys()) + list(text_by_source.keys())))\n",
    "for ds in sources:\n",
    "    v = visual_by_source.get(ds, 0)\n",
    "    t = text_by_source.get(ds, 0)\n",
    "    b = both_by_source.get(ds, 0)\n",
    "    print(f\"  {ds:<25} â†’ visual={v:<6} text={t:<6} both={b:<6}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f669a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¸¥æ ¼ç­›é€‰å®Œæˆï¼Œæœ€ç»ˆé‡‡æ · 35702 æ¡æ ·æœ¬ï¼ˆ4 â‰¤ steps â‰¤ 8ï¼‰\n",
      "ğŸ“ è¾“å‡ºæ–‡ä»¶: /projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_sampled_4to8.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "input_path = \"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_all.jsonl\"\n",
    "output_path = \"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_sampled_4to8.jsonl\"\n",
    "\n",
    "# è¯»å–æ•°æ®å¹¶æ•´ç†ä¸º {source -> {action -> [samples]}}\n",
    "sources = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            item = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        ds = item.get(\"data_source\", \"unknown\")\n",
    "        _id = item.get(\"id\", \"\")\n",
    "        parts = _id.split(\"/\")\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        action = parts[1]\n",
    "\n",
    "        # total_steps è½¬æ¢ä¸ºæ•´æ•°\n",
    "        steps = item.get(\"total_steps\")\n",
    "        if isinstance(steps, str):\n",
    "            try:\n",
    "                steps = int(steps)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        item[\"total_steps\"] = steps\n",
    "\n",
    "        # ä»…ä¿ç•™ total_steps åœ¨ [4,8] çš„æ ·æœ¬\n",
    "        if not (4 <= steps <= 8):\n",
    "            continue\n",
    "\n",
    "        sources[ds][action].append(item)\n",
    "\n",
    "# è®¡ç®—æ¯ä¸ª source çš„ visual/text æ¯”ä¾‹\n",
    "source_stats = {}\n",
    "for ds, actions in sources.items():\n",
    "    visual_count = 0\n",
    "    text_count = 0\n",
    "    for samples in actions.values():\n",
    "        for s in samples:\n",
    "            if \"visual_demo\" in s:\n",
    "                visual_count += 1\n",
    "            if \"text_demo\" in s:\n",
    "                text_count += 1\n",
    "    total = visual_count + text_count\n",
    "    if total == 0:\n",
    "        continue\n",
    "    source_stats[ds] = {\n",
    "        \"visual_ratio\": visual_count / total,\n",
    "        \"text_ratio\": text_count / total,\n",
    "        \"total\": total\n",
    "    }\n",
    "\n",
    "# å¼€å§‹é‡‡æ ·\n",
    "target_total = 40000\n",
    "total_source = len(source_stats)\n",
    "avg_per_source = target_total // total_source\n",
    "\n",
    "selected = []\n",
    "\n",
    "for ds, actions in sources.items():\n",
    "    # å½“å‰ source çš„ç›®æ ‡æ¯”ä¾‹\n",
    "    ratios = source_stats.get(ds, {\"visual_ratio\": 1.0, \"text_ratio\": 0.0})\n",
    "    n_vis = int(avg_per_source * ratios[\"visual_ratio\"])\n",
    "    n_txt = int(avg_per_source * ratios[\"text_ratio\"])\n",
    "\n",
    "    # åŠ¨ä½œåˆ†ç±»\n",
    "    visual_actions = []\n",
    "    text_actions = []\n",
    "\n",
    "    for action, samples in actions.items():\n",
    "        has_visual = any(\"visual_demo\" in s for s in samples)\n",
    "        has_text = any(\"text_demo\" in s for s in samples)\n",
    "        if has_visual:\n",
    "            visual_actions.append((action, samples))\n",
    "        if has_text:\n",
    "            text_actions.append((action, samples))\n",
    "\n",
    "    # éšæœºæ‰“ä¹±åŠ¨ä½œ\n",
    "    random.shuffle(visual_actions)\n",
    "    random.shuffle(text_actions)\n",
    "\n",
    "    def pick_actions(actions_list, target_n):\n",
    "        chosen = []\n",
    "        for act, samples in actions_list:\n",
    "            if len(chosen) >= target_n:\n",
    "                break\n",
    "            chosen.extend(samples)\n",
    "        return chosen\n",
    "\n",
    "    selected.extend(pick_actions(visual_actions, n_vis))\n",
    "    selected.extend(pick_actions(text_actions, n_txt))\n",
    "\n",
    "# æ‰“ä¹±ç»“æœ\n",
    "random.shuffle(selected)\n",
    "\n",
    "# å†™å‡ºç»“æœ\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as out:\n",
    "    for item in selected:\n",
    "        out.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… ä¸¥æ ¼ç­›é€‰å®Œæˆï¼Œæœ€ç»ˆé‡‡æ · {len(selected)} æ¡æ ·æœ¬ï¼ˆ4 â‰¤ steps â‰¤ 8ï¼‰\")\n",
    "print(f\"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73e0951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import random\n",
    "# from collections import defaultdict\n",
    "\n",
    "# input_path = \"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_all.jsonl\"\n",
    "# output_path = \"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_all_visual_tiny.jsonl\"\n",
    "\n",
    "# # è¯»å–æ•°æ®\n",
    "# data_by_source = defaultdict(list)\n",
    "\n",
    "# with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     for line in f:\n",
    "#         try:\n",
    "#             item = json.loads(line)\n",
    "#         except json.JSONDecodeError:\n",
    "#             continue\n",
    "\n",
    "#         # åªä¿ç•™æœ‰ visual_demo çš„æ ·æœ¬\n",
    "#         if \"visual_demo\" not in item:\n",
    "#             continue\n",
    "\n",
    "#         ds = item.get(\"data_source\", \"unknown\")\n",
    "#         steps = item.get(\"total_steps\")\n",
    "#         if isinstance(steps, str):\n",
    "#             try:\n",
    "#                 steps = int(steps)\n",
    "#             except ValueError:\n",
    "#                 continue\n",
    "#         item[\"total_steps\"] = steps\n",
    "#         data_by_source[ds].append(item)\n",
    "\n",
    "# # æŒ‰ data_source å’Œ step åˆ†å¸ƒå–æ ·\n",
    "# selected = []\n",
    "# for ds, items in data_by_source.items():\n",
    "#     # æŒ‰ step åˆ†ç»„\n",
    "#     step_groups = defaultdict(list)\n",
    "#     for it in items:\n",
    "#         step_groups[it[\"total_steps\"]].append(it)\n",
    "\n",
    "#     # æ¯ç§ step æ•°æœ€å¤šå– 5 ä¸ª\n",
    "#     subset = []\n",
    "#     for step_val, group in step_groups.items():\n",
    "#         random.shuffle(group)\n",
    "#         subset.extend(group[:5])\n",
    "\n",
    "#     # é™åˆ¶æ¯ä¸ª source æœ€å¤§å– 50 æ¡\n",
    "#     random.shuffle(subset)\n",
    "#     subset = subset[:50]\n",
    "#     selected.extend(subset)\n",
    "\n",
    "# # å¦‚æœè¶…è¿‡200æ¡ï¼Œéšæœºæˆªæ–­\n",
    "# random.shuffle(selected)\n",
    "# selected = selected[:200]\n",
    "\n",
    "# # å†™å…¥è¾“å‡ºæ–‡ä»¶\n",
    "# with open(output_path, \"w\", encoding=\"utf-8\") as out:\n",
    "#     for item in selected:\n",
    "#         out.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# print(f\"âœ… å·²ç”Ÿæˆ tiny visual demo æ–‡ä»¶ï¼Œå…± {len(selected)} æ¡æ ·æœ¬\")\n",
    "# print(f\"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4c431c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "\n",
    "# input_path = \"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_all1.jsonl\"\n",
    "# output_path = \"/projects/b1222/userdata/jianshu/chengxuan/ProgressLM/data/train/rl/rl_all.jsonl\"\n",
    "\n",
    "# count = 0\n",
    "\n",
    "# with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "#     for line in infile:\n",
    "#         line = line.strip()\n",
    "#         if not line:\n",
    "#             continue\n",
    "#         try:\n",
    "#             data = json.loads(line)\n",
    "#         except json.JSONDecodeError:\n",
    "#             continue\n",
    "\n",
    "#         ds = data.get(\"data_source\", \"\")\n",
    "#         if ds.startswith(\"robomind_\"):\n",
    "#             data[\"data_source\"] = ds.replace(\"robomind_\", \"\", 1)\n",
    "#             count += 1\n",
    "\n",
    "#         outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# print(f\"âœ… ä¿®æ”¹å®Œæˆï¼å…±æ›´æ–° {count} æ¡è®°å½•ã€‚\")\n",
    "# print(f\"è¾“å‡ºæ–‡ä»¶: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3vl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
