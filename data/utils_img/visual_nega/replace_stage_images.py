#!/usr/bin/env python3
"""
ä½¿ç”¨ jina-clip-v2 å¯¹ stage_to_estimate å›¾ç‰‡è¿›è¡Œç›¸ä¼¼åº¦åŒ¹é…å’Œæ›¿æ¢
ä¼˜åŒ–ç‰ˆï¼šæ”¯æŒå¤šGPUå¹¶è¡Œå¤„ç†
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Tuple
import numpy as np
from PIL import Image
import torch
from transformers import AutoModel
from tqdm import tqdm
from collections import defaultdict

# ==================== é…ç½®å‚æ•° ====================
INPUT_JSONL = "/projects/p32958/chengxuan/ProgressLM/data/train/visual_demo/visual_negative_trans_img_raw.jsonl"
OUTPUT_JSONL = "/projects/p32958/chengxuan/ProgressLM/data/train/visual_demo/visual_negative_trans_img_replaced.jsonl"
IMAGE_DIR = "/projects/p32958/chengxuan/new_extracted_images/images/visual_negative_replacement"
LOG_FILE = "/projects/p32958/chengxuan/ProgressLM/data/utils_img/visual_nega/replacement_log.json"

BATCH_SIZE = 512  # H100 å¯ä»¥å¤„ç†æ›´å¤§çš„ batch
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
GPU_IDS = [0, 1, 2, 3]  # æŒ‡å®šä½¿ç”¨çš„GPU ID
NUM_GPUS = len(GPU_IDS)

print(f"ğŸš€ ä½¿ç”¨ {NUM_GPUS} å— GPU: {GPU_IDS}")
print(f"ğŸ“¦ æ‰¹å¤„ç†å¤§å°: {BATCH_SIZE}")


# ==================== å·¥å…·å‡½æ•° ====================
def construct_image_path(record_id: str, img_name: str) -> str:
    """æ„å»ºå›¾ç‰‡å®Œæ•´è·¯å¾„"""
    # å°† id ä¸­çš„ '/' æ›¿æ¢ä¸º '_'
    safe_id = record_id.replace('/', '_')
    filename = f"{safe_id}_{img_name}"
    return os.path.join(IMAGE_DIR, filename)


def load_jsonl(file_path: str) -> List[Dict]:
    """åŠ è½½ JSONL æ–‡ä»¶"""
    print(f"ğŸ“– åŠ è½½æ•°æ®: {file_path}")
    records = []
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    for line in tqdm(lines, desc="è¯»å–JSONL"):
        records.append(json.loads(line.strip()))
    print(f"âœ… åŠ è½½äº† {len(records)} æ¡è®°å½•")
    return records


def save_jsonl(records: List[Dict], file_path: str):
    """ä¿å­˜ JSONL æ–‡ä»¶"""
    print(f"ğŸ’¾ ä¿å­˜åˆ°: {file_path}")
    with open(file_path, 'w', encoding='utf-8') as f:
        for record in tqdm(records, desc="ä¿å­˜JSONL"):
            f.write(json.dumps(record, ensure_ascii=False) + '\n')
    print(f"âœ… ä¿å­˜å®Œæˆ")


def build_candidate_pool(records: List[Dict]) -> Dict[int, List[Tuple[int, str]]]:
    """
    ä¸ºæ¯æ¡è®°å½•æ„å»ºå€™é€‰å›¾ç‰‡æ± 
    è¿”å›: {record_idx: [(candidate_record_idx, candidate_img_path), ...]}
    """
    print("ğŸ” æ„å»ºå€™é€‰å›¾ç‰‡æ± ...")

    # æŒ‰ data_source åˆ†ç»„
    data_source_groups = defaultdict(list)
    for idx, record in enumerate(records):
        data_source_groups[record['data_source']].append(idx)

    candidate_pool = {}
    missing_images = []

    for idx, record in enumerate(tqdm(records, desc="æ„å»ºå€™é€‰æ± ")):
        candidates = []
        current_data_source = record['data_source']
        current_task_goal = record['task_goal']
        current_id = record['id']

        # åœ¨ç›¸åŒ data_source çš„è®°å½•ä¸­æŸ¥æ‰¾
        for candidate_idx in data_source_groups[current_data_source]:
            if candidate_idx == idx:
                continue

            candidate_record = records[candidate_idx]

            # æ£€æŸ¥ï¼štask_goal å’Œ id å¿…é¡»ä¸åŒ
            if (candidate_record['task_goal'] != current_task_goal and
                candidate_record['id'] != current_id):

                # è·å–å€™é€‰å›¾ç‰‡ï¼ˆstage_to_estimate çš„ç¬¬ä¸€å¼ ï¼‰
                candidate_img_name = candidate_record['stage_to_estimate'][0]
                candidate_img_path = construct_image_path(
                    candidate_record['id'],
                    candidate_img_name
                )

                # éªŒè¯å›¾ç‰‡å­˜åœ¨
                if os.path.exists(candidate_img_path):
                    candidates.append((candidate_idx, candidate_img_path))
                else:
                    missing_images.append(candidate_img_path)

        candidate_pool[idx] = candidates

    if missing_images:
        print(f"âš ï¸  è­¦å‘Š: å‘ç° {len(missing_images)} å¼ å›¾ç‰‡ä¸å­˜åœ¨")
        print(f"   å‰5ä¸ªç¤ºä¾‹: {missing_images[:5]}")

    # ç»Ÿè®¡
    avg_candidates = np.mean([len(v) for v in candidate_pool.values()])
    print(f"âœ… å€™é€‰æ± æ„å»ºå®Œæˆï¼Œå¹³å‡æ¯æ¡è®°å½•æœ‰ {avg_candidates:.0f} ä¸ªå€™é€‰å›¾ç‰‡")

    return candidate_pool


def load_images_batch(image_paths: List[str], show_progress: bool = False) -> List[Image.Image]:
    """æ‰¹é‡åŠ è½½å›¾ç‰‡"""
    images = []
    iterator = tqdm(image_paths, desc="åŠ è½½å›¾ç‰‡", leave=False) if show_progress else image_paths
    for path in iterator:
        try:
            img = Image.open(path).convert('RGB')
            images.append(img)
        except Exception as e:
            print(f"âš ï¸  åŠ è½½å›¾ç‰‡å¤±è´¥: {path}, é”™è¯¯: {e}")
            # ä½¿ç”¨é»‘è‰²å ä½å›¾
            images.append(Image.new('RGB', (512, 512), color='black'))
    return images


def encode_images_batch(model, image_paths: List[str], batch_size: int) -> np.ndarray:
    """æ‰¹é‡ç¼–ç å›¾ç‰‡"""
    all_embeddings = []
    total_batches = (len(image_paths) + batch_size - 1) // batch_size

    # å¤„ç† DataParallel åŒ…è£…çš„æ¨¡å‹
    actual_model = model.module if isinstance(model, torch.nn.DataParallel) else model

    for i in tqdm(range(0, len(image_paths), batch_size),
                  desc="ç¼–ç å›¾ç‰‡",
                  total=total_batches,
                  unit="batch"):
        batch_paths = image_paths[i:i+batch_size]
        batch_images = load_images_batch(batch_paths)

        with torch.no_grad():
            embeddings = actual_model.encode_image(batch_images)
            # embeddings å·²ç»æ˜¯ numpy arrayï¼Œæ— éœ€è½¬æ¢
            if isinstance(embeddings, torch.Tensor):
                embeddings = embeddings.cpu().numpy()
            all_embeddings.append(embeddings)

    return np.vstack(all_embeddings)


# ==================== ä¸»æµç¨‹ ====================
def main():
    print("=" * 60)
    print("ğŸ¯ å¼€å§‹æ‰§è¡Œå›¾ç‰‡ç›¸ä¼¼åº¦åŒ¹é…ä»»åŠ¡")
    print("=" * 60)

    # 1. åŠ è½½æ¨¡å‹
    print("\nğŸ“¥ åŠ è½½ jina-clip-v2 æ¨¡å‹...")
    model = AutoModel.from_pretrained(
        'jinaai/jina-clip-v2',
        trust_remote_code=True
    )

    # ä½¿ç”¨å¤šGPU
    if NUM_GPUS > 1:
        print(f"ğŸ”§ å¯ç”¨ {NUM_GPUS} å— GPU å¹¶è¡Œå¤„ç†: {GPU_IDS}")
        model = torch.nn.DataParallel(model, device_ids=GPU_IDS)
        model = model.to(f'cuda:{GPU_IDS[0]}')
    else:
        model = model.to(DEVICE)

    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    # 2. åŠ è½½æ•°æ®
    records = load_jsonl(INPUT_JSONL)

    # 3. æ„å»ºå€™é€‰æ± 
    candidate_pool = build_candidate_pool(records)

    # 4. æ”¶é›†æ‰€æœ‰éœ€è¦ç¼–ç çš„å›¾ç‰‡
    print("\nğŸ“Š æ”¶é›†æ‰€æœ‰éœ€è¦ç¼–ç çš„å›¾ç‰‡...")
    all_images = set()

    # æ”¶é›†æ‰€æœ‰ stage_to_estimate å›¾ç‰‡
    for record in tqdm(records, desc="æ”¶é›†stage_to_estimateå›¾ç‰‡"):
        img_path = construct_image_path(record['id'], record['stage_to_estimate'][0])
        all_images.add(img_path)

    # æ”¶é›†æ‰€æœ‰å€™é€‰å›¾ç‰‡
    for candidates in tqdm(candidate_pool.values(), desc="æ”¶é›†å€™é€‰å›¾ç‰‡"):
        for _, img_path in candidates:
            all_images.add(img_path)

    all_images = list(all_images)
    print(f"âœ… å…±éœ€ç¼–ç  {len(all_images)} å¼ å”¯ä¸€å›¾ç‰‡")

    # 5. æ‰¹é‡ç¼–ç æ‰€æœ‰å›¾ç‰‡
    print("\nğŸ¨ å¼€å§‹æ‰¹é‡ç¼–ç å›¾ç‰‡...")
    embeddings_array = encode_images_batch(model, all_images, BATCH_SIZE)

    # æ„å»ºè·¯å¾„åˆ°åµŒå…¥çš„æ˜ å°„
    image_to_embedding = {path: emb for path, emb in zip(all_images, embeddings_array)}
    print(f"âœ… ç¼–ç å®Œæˆï¼ŒåµŒå…¥ç»´åº¦: {embeddings_array.shape[1]}")

    # 6. ç›¸ä¼¼åº¦åŒ¹é…
    print("\nğŸ”— å¼€å§‹ç›¸ä¼¼åº¦åŒ¹é…...")
    replacement_log = []

    with tqdm(total=len(records), desc="åŒ¹é…è¿›åº¦", unit="record") as pbar:
        for idx, record in enumerate(records):
            # è·å–å½“å‰å›¾ç‰‡çš„åµŒå…¥
            current_img_name = record['stage_to_estimate'][0]
            current_img_path = construct_image_path(record['id'], current_img_name)

            if current_img_path not in image_to_embedding:
                pbar.set_postfix_str(f"âš ï¸ è·³è¿‡: å›¾ç‰‡ä¸å­˜åœ¨")
                pbar.update(1)
                continue

            current_embedding = image_to_embedding[current_img_path]

            # è·å–å€™é€‰æ± 
            candidates = candidate_pool[idx]

            if not candidates:
                pbar.set_postfix_str(f"âš ï¸ è·³è¿‡: æ— å€™é€‰")
                pbar.update(1)
                continue

            # è®¡ç®—ç›¸ä¼¼åº¦
            max_similarity = -1
            best_candidate_idx = None
            best_img_filename = None  # å®Œæ•´çš„æ–‡ä»¶åï¼ˆå¸¦ safe_id å‰ç¼€ï¼‰
            best_original_img_name = None  # åŸå§‹å›¾ç‰‡åï¼ˆç”¨äºæ—¥å¿—ï¼‰

            for candidate_idx, candidate_img_path in candidates:
                candidate_embedding = image_to_embedding[candidate_img_path]

                # ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆå½’ä¸€åŒ–åçš„ç‚¹ç§¯ï¼‰
                similarity = np.dot(current_embedding, candidate_embedding)

                if similarity > max_similarity:
                    max_similarity = similarity
                    best_candidate_idx = candidate_idx
                    # ä»å®Œæ•´è·¯å¾„ä¸­æå–æ–‡ä»¶å
                    best_img_filename = os.path.basename(candidate_img_path)
                    best_original_img_name = records[candidate_idx]['stage_to_estimate'][0]

            # æ›¿æ¢
            if best_img_filename:
                original_img = record['stage_to_estimate'][0]
                record['stage_to_estimate'] = [best_img_filename]  # ä½¿ç”¨å®Œæ•´æ–‡ä»¶å

                replacement_log.append({
                    'record_idx': idx,
                    'record_id': record['id'],
                    'original_image': original_img,
                    'replaced_image': best_img_filename,  # å®Œæ•´æ–‡ä»¶å
                    'replaced_original_name': best_original_img_name,  # åŸå§‹å›¾ç‰‡åï¼ˆç”¨äºå‚è€ƒï¼‰
                    'similarity_score': float(max_similarity),
                    'source_record_id': records[best_candidate_idx]['id']
                })

                pbar.set_postfix_str(f"å·²æ›¿æ¢: {len(replacement_log)}, ç›¸ä¼¼åº¦: {max_similarity:.4f}")

            pbar.update(1)

    print(f"âœ… å®Œæˆ {len(replacement_log)} æ¡è®°å½•çš„æ›¿æ¢")

    # 7. ä¿å­˜ç»“æœ
    save_jsonl(records, OUTPUT_JSONL)

    # 8. ä¿å­˜æ—¥å¿—
    print(f"\nğŸ“ ä¿å­˜æ›¿æ¢æ—¥å¿—...")
    with open(LOG_FILE, 'w', encoding='utf-8') as f:
        json.dump({
            'total_records': len(records),
            'replaced_records': len(replacement_log),
            'avg_similarity': np.mean([r['similarity_score'] for r in replacement_log]),
            'min_similarity': np.min([r['similarity_score'] for r in replacement_log]),
            'max_similarity': np.max([r['similarity_score'] for r in replacement_log]),
            'details': replacement_log
        }, f, indent=2, ensure_ascii=False)
    print(f"âœ… æ—¥å¿—ä¿å­˜åˆ°: {LOG_FILE}")

    # 9. ç»Ÿè®¡æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š æ‰§è¡Œç»Ÿè®¡")
    print("=" * 60)
    print(f"æ€»è®°å½•æ•°: {len(records)}")
    print(f"æˆåŠŸæ›¿æ¢: {len(replacement_log)}")
    print(f"æ›¿æ¢ç‡: {len(replacement_log)/len(records)*100:.2f}%")
    print(f"å¹³å‡ç›¸ä¼¼åº¦: {np.mean([r['similarity_score'] for r in replacement_log]):.4f}")
    print(f"ç›¸ä¼¼åº¦èŒƒå›´: [{np.min([r['similarity_score'] for r in replacement_log]):.4f}, "
          f"{np.max([r['similarity_score'] for r in replacement_log]):.4f}]")
    print("=" * 60)
    print("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")


if __name__ == "__main__":
    main()
