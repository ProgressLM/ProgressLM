{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d69d4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking samples:   0%|          | 0/56952 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking samples: 100%|██████████| 56952/56952 [00:02<00:00, 27793.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 检查完成 ===\n",
      "总样本数          : 56952\n",
      "缺失图像样本数     : 56952\n",
      "缺失图像总数量     : 56952\n",
      "缺失图像路径已保存到 missing_images.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 配置路径\n",
    "JSONL_PATH = \"/home/runsheng/personal_3/qiancx/ProgressLM/data/h5_agilex_3rgb_converted.jsonl\"\n",
    "IMAGE_ROOT = \"/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/images\"\n",
    "\n",
    "missing_images = 0\n",
    "missing_samples = 0\n",
    "total_samples = 0\n",
    "\n",
    "# 可选：保存缺失详情\n",
    "missing_details = []\n",
    "\n",
    "with open(JSONL_PATH, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in tqdm(lines, desc=\"Checking samples\"):\n",
    "    total_samples += 1\n",
    "    sample = json.loads(line.strip())\n",
    "    sample_id = sample[\"id\"]\n",
    "    image_missing_in_sample = False  # 本样本是否缺失\n",
    "\n",
    "    # 遍历所有可能包含图片的字段\n",
    "    for field in [\"visual_demo\", \"stage_to_estimate\"]:\n",
    "        if field in sample and isinstance(sample[field], list):\n",
    "            for img in sample[field]:\n",
    "                full_path = os.path.join(IMAGE_ROOT, sample_id, img)\n",
    "                if not os.path.exists(full_path):\n",
    "                    missing_images += 1\n",
    "                    image_missing_in_sample = True\n",
    "                    missing_details.append(full_path)\n",
    "\n",
    "    if image_missing_in_sample:\n",
    "        missing_samples += 1\n",
    "\n",
    "# ====== 总结统计 ======\n",
    "print(\"\\n=== 检查完成 ===\")\n",
    "print(f\"总样本数          : {total_samples}\")\n",
    "print(f\"缺失图像样本数     : {missing_samples}\")\n",
    "print(f\"缺失图像总数量     : {missing_images}\")\n",
    "\n",
    "# 可选：保存缺失文件详情\n",
    "if missing_images > 0:\n",
    "    with open(\"missing_images.txt\", \"w\") as out:\n",
    "        out.write(\"\\n\".join(missing_details))\n",
    "    print(\"缺失图像路径已保存到 missing_images.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac7154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW PATH: /home/runsheng/personal_3/qiancx/Sources/datasets/robomind/images/h5_agilex_3rgb/10_packplate_2/2024_09_28-16_27_42-172863566445571200.00/camera_front_0000.jpg\n",
      "REPR PATH: '/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/images/h5_agilex_3rgb/10_packplate_2/2024_09_28-16_27_42-172863566445571200.00/camera_front_0000.jpg'\n",
      "os.path.exists: True\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "JSONL_PATH = \"/home/runsheng/personal_3/qiancx/ProgressLM/data/h5_agilex_3rgb_converted.jsonl\"\n",
    "IMAGE_ROOT = \"/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/images\"\n",
    "\n",
    "with open(JSONL_PATH, \"r\") as f:\n",
    "    first_line = f.readline().strip()\n",
    "    sample = json.loads(first_line)\n",
    "\n",
    "sample_id = sample[\"id\"]\n",
    "img = sample[\"visual_demo\"][0]\n",
    "\n",
    "full_path = os.path.join(IMAGE_ROOT, sample_id, img)\n",
    "\n",
    "print(\"RAW PATH:\", full_path)\n",
    "print(\"REPR PATH:\", repr(full_path))\n",
    "print(\"os.path.exists:\", os.path.exists(full_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e1c772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying images:   0%|          | 0/16359 [00:00<?, ?sample/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying images: 100%|██████████| 16359/16359 [00:00<00:00, 34748.55sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 检查完成 ===\n",
      "总样本数              : 16359\n",
      "应检查图像总数        : 132495\n",
      "已存在图像总数        : 132495\n",
      "缺失图像总数量        : 0\n",
      "缺失图像样本数        : 0\n",
      "\n",
      "任务结束 ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "JSONL_PATH = \"/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/progrsslm/annotation/h5_tienkung_xsens_frm/h5_tienkung_xsens_frm.jsonl\"\n",
    "IMAGE_ROOT = \"/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/progrsslm/images\"\n",
    "SAVE_MISSING = True\n",
    "MISSING_OUTPUT = \"missing_images.txt\"\n",
    "\n",
    "# —— 统计量 —— #\n",
    "total_samples = 0\n",
    "expected_images_total = 0\n",
    "existing_images_total = 0\n",
    "missing_images = 0\n",
    "missing_samples = 0\n",
    "\n",
    "missing_details = []\n",
    "\n",
    "def iter_images_in_sample(sample):\n",
    "    \"\"\"把需要检查的所有图片名统一产出（确保是 list 且去掉空白）\"\"\"\n",
    "    fields = [\"visual_demo\", \"stage_to_estimate\"]\n",
    "    for field in fields:\n",
    "        v = sample.get(field, [])\n",
    "        if isinstance(v, str):\n",
    "            v = [v]\n",
    "        if not isinstance(v, list):\n",
    "            continue\n",
    "        for x in v:\n",
    "            x = (x or \"\").strip()\n",
    "            if x:\n",
    "                yield x\n",
    "\n",
    "with open(JSONL_PATH, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in tqdm(lines, desc=\"Verifying images\", unit=\"sample\"):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    # —— 解析 JSON —— #\n",
    "    try:\n",
    "        sample = json.loads(line)\n",
    "    except json.JSONDecodeError:\n",
    "        # 解析失败：这个样本不计入图像统计（也可选择计为缺失样本，看你需求）\n",
    "        continue\n",
    "\n",
    "    total_samples += 1\n",
    "    sample_id = (sample.get(\"id\") or \"\").strip()\n",
    "    if not sample_id:\n",
    "        # id 缺失：该样本无法定位任何图片，按“0 张应检查图像”处理\n",
    "        # 也可以选择：missing_samples += 1（但这会混淆口径，不建议）\n",
    "        continue\n",
    "\n",
    "    # —— 逐图统计（关键） —— #\n",
    "    missing_this_sample = 0\n",
    "    for img_name in iter_images_in_sample(sample):\n",
    "        expected_images_total += 1\n",
    "        full_path = os.path.join(IMAGE_ROOT, sample_id, img_name)\n",
    "        if os.path.exists(full_path):\n",
    "            existing_images_total += 1\n",
    "        else:\n",
    "            missing_images += 1\n",
    "            missing_this_sample += 1\n",
    "            if SAVE_MISSING:\n",
    "                missing_details.append(full_path)\n",
    "\n",
    "    # 只要该样本有至少 1 张缺失，就+1（逐样本计数）\n",
    "    if missing_this_sample > 0:\n",
    "        missing_samples += 1\n",
    "\n",
    "# —— 汇总与自检 —— #\n",
    "print(\"\\n=== 检查完成 ===\")\n",
    "print(f\"总样本数              : {total_samples}\")\n",
    "print(f\"应检查图像总数        : {expected_images_total}\")\n",
    "print(f\"已存在图像总数        : {existing_images_total}\")\n",
    "print(f\"缺失图像总数量        : {missing_images}\")\n",
    "print(f\"缺失图像样本数        : {missing_samples}\")\n",
    "\n",
    "# 一致性检查（出现不一致就提示）\n",
    "if expected_images_total != existing_images_total + missing_images:\n",
    "    print(\"\\n[警告] 期望数量 != 存在 + 缺失，请检查统计逻辑或上游数据！\")\n",
    "    print(f\"  expected_images_total = {expected_images_total}\")\n",
    "    print(f\"  existing_images_total = {existing_images_total}\")\n",
    "    print(f\"  missing_images        = {missing_images}\")\n",
    "\n",
    "if SAVE_MISSING and missing_details:\n",
    "    with open(MISSING_OUTPUT, \"w\") as f:\n",
    "        f.write(\"\\n\".join(missing_details))\n",
    "    print(f\"\\n缺失图像路径已保存到：{MISSING_OUTPUT}\")\n",
    "\n",
    "print(\"\\n任务结束 ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fac271a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/runsheng/personal_3/qiancx/ProgressLM/data/h5_agilex_3rgb_converted.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m x\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# === 读取输入 JSONL === #\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mJSONL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     35\u001b[0m     lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# === 输出 JSONL === #\u001b[39;00m\n",
      "File \u001b[0;32m~/personal/yueqi/anaconda3/envs/qeval/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/runsheng/personal_3/qiancx/ProgressLM/data/h5_agilex_3rgb_converted.jsonl'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === 配置区 === #\n",
    "JSONL_PATH = \"/home/runsheng/personal_3/qiancx/ProgressLM/data/h5_agilex_3rgb_converted.jsonl\"\n",
    "IMAGE_ROOT = \"/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/images\"\n",
    "OUTPUT_JSONL = \"/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/progrsslm/annotation/h5_agilex_3rgb——filtered.jsonl\"       # 输出的新 jsonl\n",
    "SAVE_MISSING = False\n",
    "MISSING_OUTPUT = \"missing_images.txt\"\n",
    "\n",
    "# === 统计量 === #\n",
    "total_samples = 0\n",
    "kept_samples = 0\n",
    "removed_samples = 0\n",
    "\n",
    "missing_details = []  # 记录缺失图片路径（可选）\n",
    "\n",
    "def iter_images_in_sample(sample):\n",
    "    \"\"\"统一提取需要检查的所有图片名称\"\"\"\n",
    "    fields = [\"visual_demo\", \"stage_to_estimate\"]\n",
    "    for field in fields:\n",
    "        v = sample.get(field, [])\n",
    "        if isinstance(v, str):\n",
    "            v = [v]\n",
    "        if not isinstance(v, list):\n",
    "            continue\n",
    "        for x in v:\n",
    "            x = (x or \"\").strip()\n",
    "            if x:\n",
    "                yield x\n",
    "\n",
    "# === 读取输入 JSONL === #\n",
    "with open(JSONL_PATH, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# === 输出 JSONL === #\n",
    "f_out = open(OUTPUT_JSONL, \"w\")\n",
    "\n",
    "for line in tqdm(lines, desc=\"Processing samples\", unit=\"sample\"):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        sample = json.loads(line)\n",
    "    except json.JSONDecodeError:\n",
    "        continue\n",
    "\n",
    "    total_samples += 1\n",
    "    sample_id = (sample.get(\"id\") or \"\").strip()\n",
    "    if not sample_id:\n",
    "        # id 缺失，无论如何很难匹配图片，直接丢弃该样本\n",
    "        removed_samples += 1\n",
    "        continue\n",
    "\n",
    "    # 检查该样本是否存在图片缺失\n",
    "    missing_this_sample = False\n",
    "    for img_name in iter_images_in_sample(sample):\n",
    "        full_path = os.path.join(IMAGE_ROOT, sample_id, img_name)\n",
    "        if not os.path.exists(full_path):\n",
    "            missing_this_sample = True\n",
    "            if SAVE_MISSING:\n",
    "                missing_details.append(full_path)\n",
    "            # 发现缺失可直接跳出，无需继续检查\n",
    "            break\n",
    "\n",
    "    # 如果有缺失 => 丢弃整个样本\n",
    "    if missing_this_sample:\n",
    "        removed_samples += 1\n",
    "    else:\n",
    "        kept_samples += 1\n",
    "        f_out.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "f_out.close()\n",
    "\n",
    "# === 输出统计信息 === #\n",
    "print(\"\\n=== 处理完成 ===\")\n",
    "print(f\"总样本数           : {total_samples}\")\n",
    "print(f\"保留样本数         : {kept_samples}\")\n",
    "print(f\"删除样本数         : {removed_samples}\")\n",
    "print(f\"输出文件           : {OUTPUT_JSONL}\")\n",
    "\n",
    "if SAVE_MISSING and missing_details:\n",
    "    with open(MISSING_OUTPUT, \"w\") as f:\n",
    "        f.write(\"\\n\".join(missing_details))\n",
    "    print(f\"缺失图片详情已保存 : {MISSING_OUTPUT}\")\n",
    "\n",
    "print(\"\\n任务结束 ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
