{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56f93fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†æ ·æœ¬:   3%|â–         | 1246/45276 [00:00<00:03, 12453.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å¤„ç†æ ·æœ¬: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45276/45276 [00:03<00:00, 11737.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "å¤„ç†å®Œæˆ!\n",
      "================================================================================\n",
      "è¾“å…¥æ ·æœ¬æ•°: 45276\n",
      "è¾“å‡ºæ ·æœ¬æ•°: 0\n",
      "ç§»é™¤æ ·æœ¬æ•°: 45276\n",
      "ä¿ç•™æ¯”ä¾‹: 0.00%\n",
      "\n",
      "æ€»å›¾ç‰‡æ•°: 482064\n",
      "ç¼ºå¤±å›¾ç‰‡æ•°: 45276\n",
      "å›¾ç‰‡å®Œæ•´æ€§: 90.61%\n",
      "\n",
      "è¾“å‡ºæ–‡ä»¶: /home/runsheng/personal_3/qiancx/ProgressLM/data/raw/visual_demo/visual_h5_agilex_3rgb_train.jsonl\n",
      "\n",
      "âš ï¸  ç§»é™¤äº† 45276 ä¸ªæœ‰ç¼ºå¤±å›¾ç‰‡çš„æ ·æœ¬\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def filter_complete_samples(input_jsonl, output_jsonl, image_root):\n",
    "    \"\"\"\n",
    "    è¿‡æ»¤æ‰æœ‰ç¼ºå¤±å›¾ç‰‡çš„æ ·æœ¬ï¼Œè¾“å‡ºæ–°çš„jsonlæ–‡ä»¶\n",
    "    \n",
    "    Args:\n",
    "        input_jsonl: è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„\n",
    "        output_jsonl: è¾“å‡ºJSONLæ–‡ä»¶è·¯å¾„\n",
    "        image_root: å›¾ç‰‡æ ¹ç›®å½•\n",
    "    \"\"\"\n",
    "    image_root = Path(image_root)\n",
    "    \n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    total_samples = 0\n",
    "    valid_samples = 0\n",
    "    removed_samples = 0\n",
    "    total_images = 0\n",
    "    missing_images = 0\n",
    "    \n",
    "    # å…ˆè®¡ç®—æ€»è¡Œæ•°\n",
    "    with open(input_jsonl, 'r', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    # å¤„ç†æ•°æ®\n",
    "    with open(input_jsonl, 'r', encoding='utf-8') as f_in, \\\n",
    "         open(output_jsonl, 'w', encoding='utf-8') as f_out:\n",
    "        \n",
    "        for line in tqdm(f_in, total=total_lines, desc=\"å¤„ç†æ ·æœ¬\"):\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                total_samples += 1\n",
    "                \n",
    "                sample_id = data.get('id', '')\n",
    "                has_missing = False\n",
    "                \n",
    "                # æ£€æŸ¥ visual_demo ä¸­çš„å›¾ç‰‡\n",
    "                visual_demo = data.get('visual_demo', [])\n",
    "                for img_name in visual_demo:\n",
    "                    img_path = image_root / sample_id / img_name\n",
    "                    total_images += 1\n",
    "                    if not img_path.exists():\n",
    "                        has_missing = True\n",
    "                        missing_images += 1\n",
    "                \n",
    "                # æ£€æŸ¥ stage_to_estimate ä¸­çš„å›¾ç‰‡\n",
    "                stage_to_estimate = data.get('stage_to_estimate', [])\n",
    "                for img_name in stage_to_estimate:\n",
    "                    img_path = image_root / sample_id / img_name\n",
    "                    total_images += 1\n",
    "                    if not img_path.exists():\n",
    "                        has_missing = True\n",
    "                        missing_images += 1\n",
    "                \n",
    "                # å¦‚æœæ‰€æœ‰å›¾ç‰‡éƒ½å­˜åœ¨ï¼Œå†™å…¥è¾“å‡ºæ–‡ä»¶\n",
    "                if not has_missing:\n",
    "                    f_out.write(line)\n",
    "                    valid_samples += 1\n",
    "                else:\n",
    "                    removed_samples += 1\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # æ‰“å°ç»Ÿè®¡ç»“æœ\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"å¤„ç†å®Œæˆ!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"è¾“å…¥æ ·æœ¬æ•°: {total_samples}\")\n",
    "    print(f\"è¾“å‡ºæ ·æœ¬æ•°: {valid_samples}\")\n",
    "    print(f\"ç§»é™¤æ ·æœ¬æ•°: {removed_samples}\")\n",
    "    print(f\"ä¿ç•™æ¯”ä¾‹: {valid_samples/total_samples*100:.2f}%\" if total_samples > 0 else \"N/A\")\n",
    "    print(f\"\\næ€»å›¾ç‰‡æ•°: {total_images}\")\n",
    "    print(f\"ç¼ºå¤±å›¾ç‰‡æ•°: {missing_images}\")\n",
    "    print(f\"å›¾ç‰‡å®Œæ•´æ€§: {(total_images-missing_images)/total_images*100:.2f}%\" if total_images > 0 else \"N/A\")\n",
    "    print(f\"\\nè¾“å‡ºæ–‡ä»¶: {output_jsonl}\")\n",
    "    \n",
    "    if removed_samples == 0:\n",
    "        print(f\"\\nâœ… æ‰€æœ‰æ ·æœ¬å›¾ç‰‡å®Œæ•´!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  ç§»é™¤äº† {removed_samples} ä¸ªæœ‰ç¼ºå¤±å›¾ç‰‡çš„æ ·æœ¬\")\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # è®¾ç½®è·¯å¾„\n",
    "#     INPUT_JSONL = '/home/vcj9002/jianshu/workspace/code/ProgressLM/data/raw/visual_demo/visual_h5_franka_3rgb_raw.jsonl'      # è¾“å…¥JSONLæ–‡ä»¶\n",
    "#     OUTPUT_JSONL = '/home/vcj9002/jianshu/workspace/code/ProgressLM/data/raw/visual_demo/visual_h5_franka_3rgb_train.jsonl'    # è¾“å‡ºJSONLæ–‡ä»¶\n",
    "#     IMAGE_ROOT = '/home/vcj9002/jianshu/workspace/data/robomind/data/images'  # å›¾ç‰‡æ ¹ç›®å½•\n",
    "    \n",
    "#     # è¿è¡Œè¿‡æ»¤\n",
    "#     filter_complete_samples(INPUT_JSONL, OUTPUT_JSONL, IMAGE_ROOT)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # è®¾ç½®è·¯å¾„\n",
    "#     INPUT_JSONL = '/home/vcj9002/jianshu/workspace/code/ProgressLM/data/eval/visual/visual_h5_franka_3rgb_t.jsonl'      # è¾“å…¥JSONLæ–‡ä»¶\n",
    "#     OUTPUT_JSONL = '/home/vcj9002/jianshu/workspace/code/ProgressLM/data/eval/visual/visual_h5_franka_3rgb_test.jsonl'    # è¾“å‡ºJSONLæ–‡ä»¶\n",
    "#     IMAGE_ROOT = '/home/vcj9002/jianshu/workspace/data/robomind/data/images'  # å›¾ç‰‡æ ¹ç›®å½•\n",
    "    \n",
    "#     # è¿è¡Œè¿‡æ»¤\n",
    "#     filter_complete_samples(INPUT_JSONL, OUTPUT_JSONL, IMAGE_ROOT)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # è®¾ç½®è·¯å¾„\n",
    "    INPUT_JSONL = '/home/runsheng/personal_3/qiancx/ProgressLM/data/raw/visual_demo/visual_h5_agilex_3rgb_t.jsonl'      # è¾“å…¥JSONLæ–‡ä»¶\n",
    "    OUTPUT_JSONL = '/home/runsheng/personal_3/qiancx/ProgressLM/data/raw/visual_demo/visual_h5_agilex_3rgb_train.jsonl'    # è¾“å‡ºJSONLæ–‡ä»¶\n",
    "    IMAGE_ROOT = '/home/runsheng/personal_3/qiancx/Sources/datasets/robomind/images'  # å›¾ç‰‡æ ¹ç›®å½•\n",
    "    \n",
    "    # è¿è¡Œè¿‡æ»¤\n",
    "    filter_complete_samples(INPUT_JSONL, OUTPUT_JSONL, IMAGE_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed70074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– è¯»å–æ–‡ä»¶: /home/runsheng/personal_3/qiancx/ProgressLM/data/raw/visual_demo/visual_h5_agilex_3rgb_t.jsonl\n",
      "\n",
      "ğŸ’¾ ä¿å­˜åˆ°: /home/runsheng/personal_3/qiancx/ProgressLM/data/raw/visual_demo/visual_h5_agilex_3rgb_t_fixed.jsonl\n",
      "\n",
      "âœ… ä¿®æ­£å®Œæˆï¼\n",
      "   æ€»è¡Œæ•°: 45276\n",
      "   ä¿®æ”¹è¡Œæ•°: 45276\n",
      "   ä¿®æ”¹å¸§æ•°: 45276\n",
      "   ä¿®æ”¹æ¯”ä¾‹: 100.0%\n",
      "\n",
      "ğŸ” éªŒè¯ä¿®æ­£ç»“æœ: /home/runsheng/personal_3/qiancx/ProgressLM/data/raw/visual_demo/visual_h5_agilex_3rgb_t_fixed.jsonl\n",
      "   stage_to_estimateä¸­çš„camera_top: 0\n",
      "   stage_to_estimateä¸­çš„camera_front: 45276\n",
      "   âœ… æ‰€æœ‰camera_topå·²æˆåŠŸæ›¿æ¢ä¸ºcamera_front\n",
      "\n",
      "ğŸ¯ ç°åœ¨å¯ä»¥ä½¿ç”¨ä¿®æ­£åçš„æ–‡ä»¶:\n",
      "   /home/runsheng/personal_3/qiancx/ProgressLM/data/raw/visual_demo/visual_h5_agilex_3rgb_t_fixed.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def fix_jsonl_camera_names(input_file: str, output_file: str = None):\n",
    "    \"\"\"\n",
    "    ä¿®æ­£JSONLæ–‡ä»¶ä¸­stage_to_estimateå­—æ®µçš„ç›¸æœºåç§°\n",
    "    å°†camera_topæ›¿æ¢ä¸ºcamera_front\n",
    "    \n",
    "    Args:\n",
    "        input_file: è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„\n",
    "        output_file: è¾“å‡ºJSONLæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸ºè¾“å…¥æ–‡ä»¶å_fixed.jsonlï¼‰\n",
    "    \"\"\"\n",
    "    input_path = Path(input_file)\n",
    "    \n",
    "    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œè‡ªåŠ¨ç”Ÿæˆ\n",
    "    if output_file is None:\n",
    "        output_file = str(input_path.parent / f\"{input_path.stem}_fixed.jsonl\")\n",
    "    \n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    total_lines = 0\n",
    "    modified_lines = 0\n",
    "    total_frames_modified = 0\n",
    "    \n",
    "    corrected_lines = []\n",
    "    \n",
    "    print(f\"ğŸ“– è¯»å–æ–‡ä»¶: {input_file}\")\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            total_lines += 1\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                line_modified = False\n",
    "                \n",
    "                # ä¿®æ­£ stage_to_estimate ä¸­çš„ç›¸æœºåç§°\n",
    "                if 'stage_to_estimate' in data and data['stage_to_estimate']:\n",
    "                    modified_frames = []\n",
    "                    for frame in data['stage_to_estimate']:\n",
    "                        if 'camera_top' in frame:\n",
    "                            # æ›¿æ¢ camera_top ä¸º camera_front\n",
    "                            new_frame = frame.replace('camera_top', 'camera_front')\n",
    "                            modified_frames.append(new_frame)\n",
    "                            total_frames_modified += 1\n",
    "                            line_modified = True\n",
    "                        else:\n",
    "                            modified_frames.append(frame)\n",
    "                    \n",
    "                    data['stage_to_estimate'] = modified_frames\n",
    "                \n",
    "                if line_modified:\n",
    "                    modified_lines += 1\n",
    "                \n",
    "                # ä¿å­˜ä¿®æ­£åçš„æ•°æ®\n",
    "                corrected_lines.append(json.dumps(data, ensure_ascii=False))\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"âš ï¸ ç¬¬ {line_num} è¡ŒJSONè§£æé”™è¯¯: {e}\")\n",
    "                corrected_lines.append(line)  # ä¿ç•™åŸå§‹è¡Œ\n",
    "    \n",
    "    # å†™å…¥ä¿®æ­£åçš„æ–‡ä»¶\n",
    "    print(f\"\\nğŸ’¾ ä¿å­˜åˆ°: {output_file}\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(corrected_lines))\n",
    "        if corrected_lines:\n",
    "            f.write('\\n')  # æœ«å°¾æ·»åŠ æ¢è¡Œç¬¦\n",
    "    \n",
    "    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"\\nâœ… ä¿®æ­£å®Œæˆï¼\")\n",
    "    print(f\"   æ€»è¡Œæ•°: {total_lines}\")\n",
    "    print(f\"   ä¿®æ”¹è¡Œæ•°: {modified_lines}\")\n",
    "    print(f\"   ä¿®æ”¹å¸§æ•°: {total_frames_modified}\")\n",
    "    print(f\"   ä¿®æ”¹æ¯”ä¾‹: {modified_lines/total_lines*100:.1f}%\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "\n",
    "def verify_fix(fixed_file: str):\n",
    "    \"\"\"\n",
    "    éªŒè¯ä¿®æ­£ç»“æœï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰camera_top\n",
    "    \n",
    "    Args:\n",
    "        fixed_file: ä¿®æ­£åçš„æ–‡ä»¶è·¯å¾„\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ” éªŒè¯ä¿®æ­£ç»“æœ: {fixed_file}\")\n",
    "    \n",
    "    camera_top_count = 0\n",
    "    camera_front_count = 0\n",
    "    \n",
    "    with open(fixed_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            data = json.loads(line)\n",
    "            for frame in data.get('stage_to_estimate', []):\n",
    "                if 'camera_top' in frame:\n",
    "                    camera_top_count += 1\n",
    "                if 'camera_front' in frame:\n",
    "                    camera_front_count += 1\n",
    "    \n",
    "    print(f\"   stage_to_estimateä¸­çš„camera_top: {camera_top_count}\")\n",
    "    print(f\"   stage_to_estimateä¸­çš„camera_front: {camera_front_count}\")\n",
    "    \n",
    "    if camera_top_count == 0:\n",
    "        print(f\"   âœ… æ‰€æœ‰camera_topå·²æˆåŠŸæ›¿æ¢ä¸ºcamera_front\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ ä»æœ‰ {camera_top_count} ä¸ªcamera_topæœªæ›¿æ¢\")\n",
    "\n",
    "\n",
    "# ========== ä½¿ç”¨ç¤ºä¾‹ ==========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ä¿®æ­£æ–‡ä»¶\n",
    "    input_file = \"/home/runsheng/personal_3/qiancx/ProgressLM/data/eval/visual/visual_h5_agilex_3rgb_test.jsonl\"\n",
    "    \n",
    "    # æ‰§è¡Œä¿®æ­£\n",
    "    output_file = fix_jsonl_camera_names(input_file)\n",
    "    \n",
    "    # éªŒè¯ä¿®æ­£ç»“æœ\n",
    "    verify_fix(output_file)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ç°åœ¨å¯ä»¥ä½¿ç”¨ä¿®æ­£åçš„æ–‡ä»¶:\")\n",
    "    print(f\"   {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
